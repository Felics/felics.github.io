<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Trendy Man</title>
    <description>万物之中 希望至美 至美之物 永不凋零</description>
    <link>http://localhost:4000/</link>
    <atom:link href="http://localhost:4000/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Tue, 14 Sep 2021 17:25:49 +0800</pubDate>
    <lastBuildDate>Tue, 14 Sep 2021 17:25:49 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>Elasticsearch架构原理</title>
        <description>&lt;h1 id=&quot;架构原理&quot;&gt;架构原理&lt;/h1&gt;

&lt;p&gt;本书作为 Elastic Stack 指南，关注于 Elasticsearch 在日志和数据分析场景的应用，并不打算对底层的 Lucene 原理或者 Java 编程做详细的介绍，但是 Elasticsearch 层面上的一些架构设计，对我们做性能调优，故障处理，具有非常重要的影响。&lt;/p&gt;

&lt;p&gt;所以，作为 ES 部分的起始章节，先从数据流向和分布的层面，介绍一下 ES 的工作原理，以及相关的可控项。各位读者可以跳过这节先行阅读后面的运维操作部分，但作为性能调优的基础知识，依然建议大家抽时间返回来了解。&lt;/p&gt;

&lt;h1 id=&quot;带着问题学习&quot;&gt;带着问题学习&lt;/h1&gt;

&lt;ol&gt;
  &lt;li&gt;写入的数据是如何变成elasticsearch里可以被检索和聚合的索引内容的？&lt;/li&gt;
  &lt;li&gt;lucene如何实现准实时索引？&lt;/li&gt;
  &lt;li&gt;什么是segment？&lt;/li&gt;
  &lt;li&gt;什么是commit？&lt;/li&gt;
  &lt;li&gt;segment的数据来自哪里？&lt;/li&gt;
  &lt;li&gt;segment在写入磁盘前就可以被检索，是因为利用了什么？&lt;/li&gt;
  &lt;li&gt;elasticsearch中的refresh操作是什么？配置项是哪个？设置的命令是什么？&lt;/li&gt;
  &lt;li&gt;refresh只是写到了文件系统缓存，那么实际写入磁盘是由什么控制呢？，如果这期间发生错误和故障，数据会不会丢失？&lt;/li&gt;
  &lt;li&gt;什么是translog日志？什么时候会被清空？什么是flush操作？配置项是什么？怎么配置？
10.什么是段合并？为什么要段合并？段合并线程配置项？段合并策略？怎么forcemerge(optimize)？&lt;/li&gt;
  &lt;li&gt;routing的规则是什么样的？replica读写过程？wait_for_active_shards参数timeout参数 ？&lt;/li&gt;
  &lt;li&gt;reroute 接口？&lt;/li&gt;
  &lt;li&gt;两种 自动发现方式？&lt;/li&gt;
&lt;/ol&gt;

&lt;h1 id=&quot;segmentbuffer和translog对实时性的影响&quot;&gt;segment、buffer和translog对实时性的影响&lt;/h1&gt;

&lt;p&gt;既然介绍数据流向，首先第一步就是：写入的数据是如何变成 Elasticsearch 里可以被检索和聚合的索引内容的？&lt;/p&gt;

&lt;p&gt;以单文件的静态层面看，每个全文索引都是一个词元的倒排索引，具体涉及到全文索引的通用知识，这里不单独介绍，有兴趣的读者可以阅读《Lucene in Action》等书籍详细了解。&lt;/p&gt;

&lt;h2 id=&quot;动态更新的-lucene-索引&quot;&gt;动态更新的 Lucene 索引&lt;/h2&gt;

&lt;p&gt;以在线动态服务的层面看，要做到实时更新条件下数据的可用和可靠，就需要在倒排索引的基础上，再做一系列更高级的处理。&lt;/p&gt;

&lt;p&gt;其实总结一下 Lucene 的处理办法，很简单，就是一句话：&lt;strong&gt;新收到的数据写到新的索引文件里&lt;/strong&gt;。&lt;/p&gt;

&lt;p&gt;Lucene 把每次生成的倒排索引，叫做一个段(segment)。然后另外使用一个 commit 文件，记录索引内所有的 segment。而生成 segment 的数据来源，则是内存中的 buffer。也就是说，动态更新过程如下：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;当前索引有 3 个 segment 可用。索引状态如图 2-1；
&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1101.png&quot; alt=&quot;A Lucene index with a commit point and three segments&quot; /&gt;
图 2-1&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;新接收的数据进入内存 buffer。索引状态如图 2-2；
&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1102.png&quot; alt=&quot;A Lucene index with new documents in the in-memory buffer, ready to commit&quot; /&gt;
图 2-2&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;内存 buffer 刷到磁盘，生成一个新的 segment，commit 文件同步更新。索引状态如图 2-3。
&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1103.png&quot; alt=&quot;After a commit, a new segment is added to the index and the buffer is cleared&quot; /&gt;
图 2-3&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;利用磁盘缓存实现的准实时检索&quot;&gt;利用磁盘缓存实现的准实时检索&lt;/h2&gt;

&lt;p&gt;既然涉及到磁盘，那么一个不可避免的问题就来了：磁盘太慢了！对我们要求实时性很高的服务来说，这种处理还不够。所以，在第 3 步的处理中，还有一个中间状态：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;内存 buffer 生成一个新的 segment，刷到文件系统缓存中，Lucene 即可检索这个新 segment。索引状态如图 2-4。
&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1105.png&quot; alt=&quot;The buffer contents have been written to a segment, which is searchable, but is not yet commited&quot; /&gt;
图 2-4&lt;/li&gt;
  &lt;li&gt;文件系统缓存真正同步到磁盘上，commit 文件更新。达到图 2-3 中的状态。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;这一步刷到文件系统缓存的步骤，在 Elasticsearch 中，是默认设置为 1 秒间隔的，对于大多数应用来说，几乎就相当于是实时可搜索了。Elasticsearch 也提供了单独的 &lt;code class=&quot;highlighter-rouge&quot;&gt;/_refresh&lt;/code&gt; 接口，用户如果对 1 秒间隔还不满意的，可以主动调用该接口来保证搜索可见。&lt;/p&gt;

&lt;p&gt;&lt;em&gt;注：5.0 中还提供了一个新的请求参数：&lt;code class=&quot;highlighter-rouge&quot;&gt;?refresh=wait_for&lt;/code&gt;，可以在写入数据后不强制刷新但一直等到刷新才返回。&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;不过对于 Elastic Stack 的日志场景来说，恰恰相反，我们并不需要如此高的实时性，而是需要更快的写入性能。所以，一般来说，我们反而会通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;/_settings&lt;/code&gt; 接口或者定制 template 的方式，加大 &lt;code class=&quot;highlighter-rouge&quot;&gt;refresh_interval&lt;/code&gt; 参数：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPOST http://127.0.0.1:9200/logstash-2015.06.21/_settings -d'
{ &quot;refresh_interval&quot;: &quot;10s&quot; }
'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果是导入历史数据的场合，那甚至可以先完全关闭掉：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPUT http://127.0.0.1:9200/logstash-2015.05.01 -d'
{
  &quot;settings&quot; : {
    &quot;refresh_interval&quot;: &quot;-1&quot;
  }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;在导入完成以后，修改回来或者手动调用一次即可：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPOST http://127.0.0.1:9200/logstash-2015.05.01/_refresh
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;translog-提供的磁盘同步控制&quot;&gt;translog 提供的磁盘同步控制&lt;/h2&gt;

&lt;p&gt;既然 refresh 只是写到文件系统缓存，那么第 4 步写到实际磁盘又是有什么来控制的？如果这期间发生主机错误、硬件故障等异常情况，数据会不会丢失？&lt;/p&gt;

&lt;p&gt;这里，其实有另一个机制来控制。Elasticsearch 在把数据写入到内存 buffer 的同时，其实还另外记录了一个 translog 日志。也就是说，第 2 步并不是图 2-2 的状态，而是像图 2-5 这样：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1106.png&quot; alt=&quot;New documents are added to the in-memory buffer and appended to the transaction log&quot; /&gt;
图 2-5&lt;/p&gt;

&lt;p&gt;在第 3 和第 4 步，refresh 发生的时候，translog 日志文件依然保持原样，如图 2-6：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1108.png&quot; alt=&quot;The transaction log keeps accumulating documents&quot; /&gt;
图 2-6&lt;/p&gt;

&lt;p&gt;也就是说，如果在这期间发生异常，Elasticsearch 会从 commit 位置开始，恢复整个 translog 文件中的记录，保证数据一致性。&lt;/p&gt;

&lt;p&gt;等到真正把 segment 刷到磁盘，且 commit 文件进行更新的时候， translog 文件才清空。这一步，叫做 flush。同样，Elasticsearch 也提供了 &lt;code class=&quot;highlighter-rouge&quot;&gt;/_flush&lt;/code&gt; 接口。&lt;/p&gt;

&lt;p&gt;对于 flush 操作，Elasticsearch 默认设置为：每 30 分钟主动进行一次 flush，或者当 translog 文件大小大于 512MB (老版本是 200MB)时，主动进行一次 flush。这两个行为，可以分别通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.translog.flush_threshold_period&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.translog.flush_threshold_size&lt;/code&gt; 参数修改。&lt;/p&gt;

&lt;p&gt;如果对这两种控制方式都不满意，Elasticsearch 还可以通过 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.translog.flush_threshold_ops&lt;/code&gt; 参数，控制每收到多少条数据后 flush 一次。&lt;/p&gt;

&lt;h3 id=&quot;translog-的一致性&quot;&gt;translog 的一致性&lt;/h3&gt;

&lt;p&gt;索引数据的一致性通过 translog 保证。那么 translog 文件自己呢？&lt;/p&gt;

&lt;p&gt;默认情况下，Elasticsearch 每 5 秒，或每次请求操作结束前，会强制刷新 translog 日志到磁盘上。&lt;/p&gt;

&lt;p&gt;后者是 Elasticsearch 2.0 新加入的特性。为了保证不丢数据，每次 index、bulk、delete、update 完成的时候，一定触发刷新 translog 到磁盘上，才给请求返回 200 OK。这个改变在提高数据安全性的同时当然也降低了一点性能。&lt;/p&gt;

&lt;p&gt;如果你不在意这点可能性，还是希望性能优先，可以在 index template 里设置如下参数：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;index.translog.durability&quot;: &quot;async&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;elasticsearch-分布式索引&quot;&gt;Elasticsearch 分布式索引&lt;/h2&gt;

&lt;p&gt;大家可能注意到了，前面一段内容，一直写的是”Lucene 索引”。这个区别在于，Elasticsearch 为了完成分布式系统，对一些名词概念作了变动。&lt;em&gt;索引_成为了整个集群级别的命名，而在单个主机上的_Lucene 索引&lt;/em&gt;，则被命名为_分片(shard)_。至于数据是怎么识别到自己应该在哪个分片，请阅读稍后有关 routing 的章节。&lt;/p&gt;

&lt;h1 id=&quot;segment-merge对写入性能的影响&quot;&gt;segment merge对写入性能的影响&lt;/h1&gt;

&lt;p&gt;通过上节内容，我们知道了数据怎么进入 ES 并且如何才能让数据更快的被检索使用。其中用一句话概括了 Lucene 的设计思路就是”开新文件”。从另一个方面看，开新文件也会给服务器带来负载压力。因为默认每 1 秒，都会有一个新文件产生，每个文件都需要有文件句柄，内存，CPU 使用等各种资源。一天有 86400 秒，设想一下，每次请求要扫描一遍 86400 个文件，这个响应性能绝对好不了！&lt;/p&gt;

&lt;p&gt;为了解决这个问题，ES 会不断在后台运行任务，主动将这些零散的 segment 做数据归并，尽量让索引内只保有少量的，每个都比较大的，segment 文件。这个过程是有独立的线程来进行的，并不影响新 segment 的产生。归并过程中，索引状态如图 2-7，尚未完成的较大的 segment 是被排除在检索可见范围之外的：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1110.png&quot; alt=&quot;Two commited segments and one uncommited segment in the process of being merged into a bigger segment&quot; /&gt;
图 2-7&lt;/p&gt;

&lt;p&gt;当归并完成，较大的这个 segment 刷到磁盘后，commit 文件做出相应变更，删除之前几个小 segment，改成新的大 segment。等检索请求都从小 segment 转到大 segment 上以后，删除没用的小 segment。这时候，索引里 segment 数量就下降了，状态如图 2-8 所示：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_1111.png&quot; alt=&quot;Once merging has finished, the old segments are deleted&quot; /&gt;
图 2-8&lt;/p&gt;

&lt;h2 id=&quot;归并线程配置&quot;&gt;归并线程配置&lt;/h2&gt;

&lt;p&gt;segment 归并的过程，需要先读取 segment，归并计算，再写一遍 segment，最后还要保证刷到磁盘。可以说，这是一个非常消耗磁盘 IO 和 CPU 的任务。所以，ES 提供了对归并线程的限速机制，确保这个任务不会过分影响到其他任务。&lt;/p&gt;

&lt;p&gt;在 5.0 之前，归并线程的限速配置 &lt;code class=&quot;highlighter-rouge&quot;&gt;indices.store.throttle.max_bytes_per_sec&lt;/code&gt; 是 20MB。对于写入量较大，磁盘转速较高，甚至使用 SSD 盘的服务器来说，这个限速是明显过低的。对于 Elastic Stack 应用，社区广泛的建议是可以适当调大到 100MB或者更高。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPUT http://127.0.0.1:9200/_cluster/settings -d'
{
    &quot;persistent&quot; : {
        &quot;indices.store.throttle.max_bytes_per_sec&quot; : &quot;100mb&quot;
    }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;5.0 开始，ES 对此作了大幅度改进，使用了 Lucene 的 CMS(ConcurrentMergeScheduler) 的 auto throttle 机制，正常情况下已经不再需要手动配置 &lt;code class=&quot;highlighter-rouge&quot;&gt;indices.store.throttle.max_bytes_per_sec&lt;/code&gt; 了。官方文档中都已经删除了相关介绍，不过从源码中还是可以看到，这个值目前的默认设置是 10240 MB。&lt;/p&gt;

&lt;p&gt;归并线程的数目，ES 也是有所控制的。默认数目的计算公式是： &lt;code class=&quot;highlighter-rouge&quot;&gt;Math.min(3, Runtime.getRuntime().availableProcessors() / 2)&lt;/code&gt;。即服务器 CPU 核数的一半大于 3 时，启动 3 个归并线程；否则启动跟 CPU 核数的一半相等的线程数。相信一般做 Elastic Stack 的服务器 CPU 合数都会在 6 个以上。所以一般来说就是 3 个归并线程。如果你确定自己磁盘性能跟不上，可以降低 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.merge.scheduler.max_thread_count&lt;/code&gt; 配置，免得 IO 情况更加恶化。&lt;/p&gt;

&lt;h2 id=&quot;归并策略&quot;&gt;归并策略&lt;/h2&gt;

&lt;p&gt;归并线程是按照一定的运行策略来挑选 segment 进行归并的。主要有以下几条：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;index.merge.policy.floor_segment
默认 2MB，小于这个大小的 segment，优先被归并。&lt;/li&gt;
  &lt;li&gt;index.merge.policy.max_merge_at_once
默认一次最多归并 10 个 segment&lt;/li&gt;
  &lt;li&gt;index.merge.policy.max_merge_at_once_explicit
默认 forcemerge 时一次最多归并 30 个 segment。&lt;/li&gt;
  &lt;li&gt;index.merge.policy.max_merged_segment
默认 5 GB，大于这个大小的 segment，不用参与归并。forcemerge 除外。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据这段策略，其实我们也可以从另一个角度考虑如何减少 segment 归并的消耗以及提高响应的办法：加大 flush 间隔，尽量让每次新生成的 segment 本身大小就比较大。&lt;/p&gt;

&lt;h2 id=&quot;forcemerge-接口&quot;&gt;forcemerge 接口&lt;/h2&gt;

&lt;p&gt;既然默认的最大 segment 大小是 5GB。那么一个比较庞大的数据索引，就必然会有为数不少的 segment 永远存在，这对文件句柄，内存等资源都是极大的浪费。但是由于归并任务太消耗资源，所以一般不太选择加大 &lt;code class=&quot;highlighter-rouge&quot;&gt;index.merge.policy.max_merged_segment&lt;/code&gt; 配置，而是在负载较低的时间段，通过 forcemerge 接口，强制归并 segment。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPOST http://127.0.0.1:9200/logstash-2015-06.10/_forcemerge?max_num_segments=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;由于 forcemerge 线程对资源的消耗比普通的归并线程大得多，所以，绝对不建议对还在写入数据的热索引执行这个操作。这个问题对于 Elastic Stack 来说非常好办，一般索引都是按天分割的。更合适的任务定义方式，请阅读本书稍后的 curator 章节。&lt;/p&gt;

&lt;h1 id=&quot;routing和replica的读写过程&quot;&gt;routing和replica的读写过程&lt;/h1&gt;

&lt;p&gt;之前两节，完整介绍了在单个 Lucene 索引，即 ES 分片内的数据写入流程。现在彻底回到 ES 的分布式层面上来，当一个 ES 节点收到一条数据的写入请求时，它是如何确认这个数据应该存储在哪个节点的哪个分片上的？&lt;/p&gt;

&lt;h2 id=&quot;路由计算&quot;&gt;路由计算&lt;/h2&gt;

&lt;p&gt;作为一个没有额外依赖的简单的分布式方案，ES 在这个问题上同样选择了一个非常简洁的处理方式，对任一条数据计算其对应分片的方式如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;shard = hash(routing) % number_of_primary_shards&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;每个数据都有一个 routing 参数，默认情况下，就使用其 &lt;code class=&quot;highlighter-rouge&quot;&gt;_id&lt;/code&gt; 值。将其 &lt;code class=&quot;highlighter-rouge&quot;&gt;_id&lt;/code&gt; 值计算哈希后，对索引的主分片数取余，就是数据实际应该存储到的分片 ID。&lt;/p&gt;

&lt;p&gt;由于取余这个计算，完全依赖于分母，所以导致 ES 索引有一个限制，索引的主分片数，不可以随意修改。因为一旦主分片数不一样，所以数据的存储位置计算结果都会发生改变，索引数据就完全不可读了。&lt;/p&gt;

&lt;h2 id=&quot;副本一致性&quot;&gt;副本一致性&lt;/h2&gt;

&lt;p&gt;作为分布式系统，数据副本可算是一个标配。ES 数据写入流程，自然也涉及到副本。在有副本配置的情况下，数据从发向 ES 节点，到接到 ES 节点响应返回，流向如下(附图 2-9)：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;客户端请求发送给 Node 1 节点，注意图中 Node 1 是 Master 节点，实际完全可以不是。&lt;/li&gt;
  &lt;li&gt;Node 1 用数据的 &lt;code class=&quot;highlighter-rouge&quot;&gt;_id&lt;/code&gt; 取余计算得到应该讲数据存储到 shard 0 上。通过 cluster state 信息发现 shard 0 的主分片已经分配到了 Node 3 上。Node 1 转发请求数据给 Node 3。&lt;/li&gt;
  &lt;li&gt;Node 3 完成请求数据的索引过程，存入主分片 0。然后并行转发数据给分配有 shard 0 的副本分片的 Node 1 和 Node 2。当收到任一节点汇报副本分片数据写入成功，Node 3 即返回给初始的接收节点 Node 1，宣布数据写入成功。Node 1 返回成功响应给客户端。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;https://www.elastic.co/guide/en/elasticsearch/guide/current/images/elas_0402.png&quot; alt=&quot;Creating, indexing or deleting a single document&quot; /&gt;
图 2-9&lt;/p&gt;

&lt;p&gt;这个过程中，有几个参数可以用来控制或变更其行为：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;wait_for_active_shards
上面示例中，2 个副本分片只要有 1 个成功，就可以返回给客户端了。这点也是有配置项的。其默认值的计算来源如下：
    &lt;blockquote&gt;
      &lt;p&gt;int( (primary + number_of_replicas) / 2 ) + 1&lt;/p&gt;
    &lt;/blockquote&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;根据需要，也可以将参数设置为 one，表示仅写完主分片就返回，等同于 async；还可以设置为 all，表示等所有副本分片都写完才能返回。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;timeout
如果集群出现异常，有些分片当前不可用，ES 默认会等待 1 分钟看分片能否恢复。可以使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;?timeout=30s&lt;/code&gt; 参数来缩短这个等待时间。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;副本配置和分片配置不一样，是可以随时调整的。有些较大的索引，甚至可以在做 forcemerge 前，先把副本全部取消掉，等 optimize 完后，再重新开启副本，节约单个 segment 的重复归并消耗。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPUT http://127.0.0.1:9200/logstash-mweibo-2015.05.02/_settings -d '{
    &quot;index&quot;: { &quot;number_of_replicas&quot; : 0 }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;shard-的-allocate-控制&quot;&gt;shard 的 allocate 控制&lt;/h1&gt;

&lt;p&gt;某个 shard 分配在哪个节点上，一般来说，是由 ES 自动决定的。以下几种情况会触发分配动作：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;新索引生成&lt;/li&gt;
  &lt;li&gt;索引的删除&lt;/li&gt;
  &lt;li&gt;新增副本分片&lt;/li&gt;
  &lt;li&gt;节点增减引发的数据均衡&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;ES 提供了一系列参数详细控制这部分逻辑：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;cluster.routing.allocation.enable
该参数用来控制允许分配哪种分片。默认是 &lt;code class=&quot;highlighter-rouge&quot;&gt;all&lt;/code&gt;。可选项还包括 &lt;code class=&quot;highlighter-rouge&quot;&gt;primaries&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;new_primaries&lt;/code&gt;。&lt;code class=&quot;highlighter-rouge&quot;&gt;none&lt;/code&gt; 则彻底拒绝分片。该参数的作用，本书稍后集群升级章节会有说明。&lt;/li&gt;
  &lt;li&gt;cluster.routing.allocation.allow_rebalance
该参数用来控制什么时候允许数据均衡。默认是 &lt;code class=&quot;highlighter-rouge&quot;&gt;indices_all_active&lt;/code&gt;，即要求所有分片都正常启动成功以后，才可以进行数据均衡操作，否则的话，在集群重启阶段，会浪费太多流量了。&lt;/li&gt;
  &lt;li&gt;cluster.routing.allocation.cluster_concurrent_rebalance
该参数用来控制&lt;strong&gt;集群内&lt;/strong&gt;同时运行的数据均衡任务个数。默认是 2 个。如果有节点增减，且集群负载压力不高的时候，可以适当加大。&lt;/li&gt;
  &lt;li&gt;cluster.routing.allocation.node_initial_primaries_recoveries
该参数用来控制&lt;strong&gt;节点&lt;/strong&gt;重启时，允许同时恢复几个主分片。默认是 4 个。如果节点是多磁盘，且 IO 压力不大，可以适当加大。&lt;/li&gt;
  &lt;li&gt;cluster.routing.allocation.node_concurrent_recoveries
该参数用来控制&lt;strong&gt;节点&lt;/strong&gt;除了主分片重启恢复以外其他情况下，允许同时运行的数据恢复任务。默认是 2 个。所以，节点重启时，可以看到主分片迅速恢复完成，副本分片的恢复却很慢。除了副本分片本身数据要通过网络复制以外，并发线程本身也减少了一半。当然，这种设置也是有道理的——主分片一定是本地恢复，副本分片却需要走网络，带宽是有限的。从 ES 1.6 开始，冷索引的副本分片可以本地恢复，这个参数也就是可以适当加大了。&lt;/li&gt;
  &lt;li&gt;indices.recovery.concurrent_streams
该参数用来控制&lt;strong&gt;节点&lt;/strong&gt;从网络复制恢复副本分片时的数据流个数。默认是 3 个。可以配合上一条配置一起加大。&lt;/li&gt;
  &lt;li&gt;indices.recovery.max_bytes_per_sec
该参数用来控制&lt;strong&gt;节点&lt;/strong&gt;恢复时的速率。默认是 40MB。显然是比较小的，建议加大。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此外，ES 还有一些其他的分片分配控制策略。比如以 &lt;code class=&quot;highlighter-rouge&quot;&gt;tag&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;rack_id&lt;/code&gt; 作为区分等。一般来说，Elastic Stack 场景中使用不多。运维人员可能比较常见的策略有两种：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;磁盘限额
为了保护节点数据安全，ES 会定时(&lt;code class=&quot;highlighter-rouge&quot;&gt;cluster.info.update.interval&lt;/code&gt;，默认 30 秒)检查一下各节点的数据目录磁盘使用情况。在达到 &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster.routing.allocation.disk.watermark.low&lt;/code&gt; (默认 85%)的时候，新索引分片就不会再分配到这个节点上了。在达到 &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster.routing.allocation.disk.watermark.high&lt;/code&gt; (默认 90%)的时候，就会触发该节点现存分片的数据均衡，把数据挪到其他节点上去。这两个值不但可以写百分比，还可以写具体的字节数。有些公司可能出于成本考虑，对磁盘使用率有一定的要求，需要适当抬高这个配置：&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPUT localhost:9200/_cluster/settings -d '{
    &quot;transient&quot; : {
        &quot;cluster.routing.allocation.disk.watermark.low&quot; : &quot;85%&quot;,
        &quot;cluster.routing.allocation.disk.watermark.high&quot; : &quot;10gb&quot;,
        &quot;cluster.info.update.interval&quot; : &quot;1m&quot;
    }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ol&gt;
  &lt;li&gt;热索引分片不均
默认情况下，ES 集群的数据均衡策略是以各节点的分片总数(&lt;em&gt;indices_all_active&lt;/em&gt;)作为基准的。这对于搜索服务来说无疑是均衡搜索压力提高性能的好办法。但是对于 Elastic Stack 场景，一般压力集中在新索引的数据写入方面。正常运行的时候，也没有问题。但是当集群扩容时，新加入集群的节点，分片总数远远低于其他节点。这时候如果有新索引创建，ES 的默认策略会导致新索引的所有主分片几乎全分配在这台新节点上。整个集群的写入压力，压在一个节点上，结果很可能是这个节点直接被压死，集群出现异常。
所以，对于 Elastic Stack 场景，强烈建议大家预先计算好索引的分片数后，配置好单节点分片的限额。比如，一个 5 节点的集群，索引主分片 10 个，副本 1 份。则平均下来每个节点应该有 4 个分片，那么就配置：&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -s -XPUT http://127.0.0.1:9200/logstash-2015.05.08/_settings -d '{
    &quot;index&quot;: { &quot;routing.allocation.total_shards_per_node&quot; : &quot;5&quot; }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意，这里配置的是 5 而不是 4。因为我们需要预防有机器故障，分片发生迁移的情况。如果写的是 4，那么分片迁移会失败。&lt;/p&gt;

&lt;p&gt;此外，另一种方式则更加玄妙，Elasticsearch 中有一系列参数，相互影响，最终联合决定分片分配：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;cluster.routing.allocation.balance.shard
节点上分配分片的权重，默认为 0.45。数值越大越倾向于在节点层面均衡分片。&lt;/li&gt;
  &lt;li&gt;cluster.routing.allocation.balance.index
每个索引往单个节点上分配分片的权重，默认为 0.55。数值越大越倾向于在索引层面均衡分片。&lt;/li&gt;
  &lt;li&gt;cluster.routing.allocation.balance.threshold
大于阈值则触发均衡操作。默认为1。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Elasticsearch 中的计算方法是：&lt;/p&gt;

&lt;p&gt;(indexBalance _ (node.numShards(index) – avgShardsPerNode(index)) + shardBalance _ (node.numShards() – avgShardsPerNode)) &amp;lt;=&amp;gt; weightthreshold&lt;/p&gt;

&lt;p&gt;所以，也可以采取加大 &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster.routing.allocation.balance.index&lt;/code&gt;，甚至设置 &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster.routing.allocation.balance.shard&lt;/code&gt; 为 0 来尽量采用索引内的节点均衡。&lt;/p&gt;

&lt;h2 id=&quot;reroute-接口&quot;&gt;reroute 接口&lt;/h2&gt;

&lt;p&gt;上面说的各种配置，都是从策略层面，控制分片分配的选择。在必要的时候，还可以通过 ES 的 reroute 接口，手动完成对分片的分配选择的控制。&lt;/p&gt;

&lt;p&gt;reroute 接口支持五种指令：&lt;code class=&quot;highlighter-rouge&quot;&gt;allocate_replica&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;allocate_stale_primary&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;allocate_empty_primary&lt;/code&gt;，&lt;code class=&quot;highlighter-rouge&quot;&gt;move&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;cancel&lt;/code&gt;。常用的一般是 allocate 和 move：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;allocate_*&lt;/code&gt; 指令&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为负载过高等原因，有时候个别分片可能长期处于 UNASSIGNED 状态，我们就可以手动分配分片到指定节点上。默认情况下只允许手动分配副本分片(即使用 &lt;code class=&quot;highlighter-rouge&quot;&gt;allocate_replica&lt;/code&gt;)，所以如果要分配主分片，需要单独加一个 &lt;code class=&quot;highlighter-rouge&quot;&gt;accept_data_loss&lt;/code&gt; 选项：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;# curl -XPOST 127.0.0.1:9200/_cluster/reroute -d '{
  &quot;commands&quot; : [ {
        &quot;allocate_stale_primary&quot; :
            {
              &quot;index&quot; : &quot;logstash-2015.05.27&quot;, &quot;shard&quot; : 61, &quot;node&quot; : &quot;10.19.0.77&quot;, &quot;accept_data_loss&quot; : true
            }
        }
  ]
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;注意，&lt;code class=&quot;highlighter-rouge&quot;&gt;allocate_stale_primary&lt;/code&gt; 表示准备分配到的节点上可能有老版本的历史数据，运行时请提前确认一下是哪个节点上保留有这个分片的实际目录，且目录大小最大。然后手动分配到这个节点上。以此减少数据丢失。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;move 指令&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;因为负载过高，磁盘利用率过高，服务器下线，更换磁盘等原因，可以会需要从节点上移走部分分片：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPOST 127.0.0.1:9200/_cluster/reroute -d '{
  &quot;commands&quot; : [ {
        &quot;move&quot; :
            {
              &quot;index&quot; : &quot;logstash-2015.05.22&quot;, &quot;shard&quot; : 0, &quot;from_node&quot; : &quot;10.19.0.81&quot;, &quot;to_node&quot; : &quot;10.19.0.104&quot;
            }
        }
  ]
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;分配失败原因&quot;&gt;分配失败原因&lt;/h2&gt;

&lt;p&gt;如果是自己手工 reroute 失败，Elasticsearch 返回的响应中会带上失败的原因。不过格式非常难看，一堆 YES，NO。从 5.0 版本开始，Elasticsearch 新增了一个 allocation explain 接口，专门用来解释指定分片的具体失败理由：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XGET 'http://localhost:9200/_cluster/allocation/explain' -d'{
      &quot;index&quot;: &quot;logstash-2016.10.31&quot;,
      &quot;shard&quot;: 0,
      &quot;primary&quot;: false
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;得到的响应如下：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    &quot;shard&quot; : {
        &quot;index&quot; : &quot;myindex&quot;,
        &quot;index_uuid&quot; : &quot;KnW0-zELRs6PK84l0r38ZA&quot;,
        &quot;id&quot; : 0,
        &quot;primary&quot; : false
    },
    &quot;assigned&quot; : false,
    &quot;shard_state_fetch_pending&quot;: false,
    &quot;unassigned_info&quot; : {
        &quot;reason&quot; : &quot;INDEX_CREATED&quot;,
        &quot;at&quot; : &quot;2016-03-22T20:04:23.620Z&quot;
    },
    &quot;allocation_delay_ms&quot; : 0,
    &quot;remaining_delay_ms&quot; : 0,
    &quot;nodes&quot; : {
        &quot;V-Spi0AyRZ6ZvKbaI3691w&quot; : {
            &quot;node_name&quot; : &quot;H5dfFeA&quot;,
            &quot;node_attributes&quot; : {
                &quot;bar&quot; : &quot;baz&quot;
            },
            &quot;store&quot; : {
                &quot;shard_copy&quot; : &quot;NONE&quot;
            },
            &quot;final_decision&quot; : &quot;NO&quot;,
            &quot;final_explanation&quot; : &quot;the shard cannot be assigned because one or more allocation decider returns a 'NO' decision&quot;,
            &quot;weight&quot; : 0.06666675,
            &quot;decisions&quot; : [ {
                &quot;decider&quot; : &quot;filter&quot;,
                &quot;decision&quot; : &quot;NO&quot;,
                &quot;explanation&quot; : &quot;node does not match index include filters [foo:\&quot;bar\&quot;]&quot;
            }  ]
        },
        &quot;Qc6VL8c5RWaw1qXZ0Rg57g&quot; : {
            ...
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这会是很长一串 JSON，把集群里所有的节点都列上来，挨个解释为什么不能分配到这个节点。&lt;/p&gt;

&lt;h2 id=&quot;节点下线&quot;&gt;节点下线&lt;/h2&gt;

&lt;p&gt;集群中个别节点出现故障预警等情况，需要下线，也是 Elasticsearch 运维工作中常见的情况。如果已经稳定运行过一段时间的集群，每个节点上都会保存有数量不少的分片。这种时候通过 reroute 接口手动转移，就显得太过麻烦了。这个时候，有另一种方式：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPUT 127.0.0.1:9200/_cluster/settings -d '{
  &quot;transient&quot; :{
      &quot;cluster.routing.allocation.exclude._ip&quot; : &quot;10.0.0.1&quot;
   }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Elasticsearch 集群就会自动把这个 IP 上的所有分片，都自动转移到其他节点上。等到转移完成，这个空节点就可以毫无影响的下线了。&lt;/p&gt;

&lt;p&gt;和 &lt;code class=&quot;highlighter-rouge&quot;&gt;_ip&lt;/code&gt; 类似的参数还有 &lt;code class=&quot;highlighter-rouge&quot;&gt;_host&lt;/code&gt;, &lt;code class=&quot;highlighter-rouge&quot;&gt;_name&lt;/code&gt; 等。此外，这类参数不单是 cluster 级别，也可以是 index 级别。下一小节就是 index 级别的用例。&lt;/p&gt;

&lt;h2 id=&quot;冷热数据的读写分离&quot;&gt;冷热数据的读写分离&lt;/h2&gt;

&lt;p&gt;Elasticsearch 集群一个比较突出的问题是: 用户做一次大的查询的时候, 非常大量的读 IO 以及聚合计算导致机器 Load 升高, CPU 使用率上升, 会影响阻塞到新数据的写入, 这个过程甚至会持续几分钟。所以，可能需要仿照 MySQL 集群一样，做读写分离。&lt;/p&gt;

&lt;h3 id=&quot;实施方案&quot;&gt;实施方案&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;N 台机器做热数据的存储, 上面只放当天的数据。这 N 台热数据节点上面的 elasticsearc.yml 中配置 &lt;code class=&quot;highlighter-rouge&quot;&gt;node.attr.tag: hot&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;之前的数据放在另外的 M 台机器上。这 M 台冷数据节点中配置 &lt;code class=&quot;highlighter-rouge&quot;&gt;node.attr.tag: stale&lt;/code&gt;&lt;/li&gt;
  &lt;li&gt;模板中控制对新建索引添加 hot 标签：
    &lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
&quot;order&quot; : 0,
&quot;template&quot; : &quot;*&quot;,
&quot;settings&quot; : {
  &quot;index.routing.allocation.include.tag&quot; : &quot;hot&quot;
}
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;    &lt;/div&gt;
  &lt;/li&gt;
  &lt;li&gt;每天计划任务更新索引的配置, 将 tag 更改为 stale, 索引会自动迁移到 M 台冷数据节点&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl -XPUT http://127.0.0.1:9200/indexname/_settings -d'
{
   &quot;index&quot;: {
      &quot;routing&quot;: {
         &quot;allocation&quot;: {
            &quot;include&quot;: {
               &quot;tag&quot;: &quot;stale&quot;
            }
         }
     }
   }
}'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;这样，写操作集中在 N 台热数据节点上，大范围的读操作集中在 M 台冷数据节点上。避免了堵塞影响。&lt;/p&gt;

&lt;p&gt;该方案运用的，是 Elasticsearch 中的 allocation filter 功能，详细说明见：&lt;a href=&quot;https://www.elastic.co/guide/en/elasticsearch/reference/master/shard-allocation-filtering.html&quot;&gt;https://www.elastic.co/guide/en/elasticsearch/reference/master/shard-allocation-filtering.html&lt;/a&gt;&lt;/p&gt;

&lt;h1 id=&quot;集群自动发现&quot;&gt;集群自动发现&lt;/h1&gt;

&lt;p&gt;ES 是一个 P2P 类型(使用 gossip 协议)的分布式系统，除了集群状态管理以外，其他所有的请求都可以发送到集群内任意一台节点上，这个节点可以自己找到需要转发给哪些节点，并且直接跟这些节点通信。&lt;/p&gt;

&lt;p&gt;所以，从网络架构及服务配置上来说，构建集群所需要的配置极其简单。在 Elasticsearch 2.0 之前，无阻碍的网络下，所有配置了相同 &lt;code class=&quot;highlighter-rouge&quot;&gt;cluster.name&lt;/code&gt; 的节点都自动归属到一个集群中。&lt;/p&gt;

&lt;p&gt;2.0 版本之后，基于安全的考虑，Elasticsearch 稍作了调整，避免开发环境过于随便造成的麻烦。&lt;/p&gt;

&lt;h2 id=&quot;unicast-方式&quot;&gt;unicast 方式&lt;/h2&gt;

&lt;p&gt;ES 从 2.0 版本开始，默认的自动发现方式改为了单播(unicast)方式。配置里提供几台节点的地址，ES 将其视作 gossip router 角色，借以完成集群的发现。由于这只是 ES 内一个很小的功能，所以 gossip router 角色并不需要单独配置，每个 ES 节点都可以担任。所以，采用单播方式的集群，各节点都配置相同的几个节点列表作为 router 即可。&lt;/p&gt;

&lt;p&gt;此外，考虑到节点有时候因为高负载，慢 GC 等原因可能会有偶尔没及时响应 ping 包的可能，一般建议稍微加大 Fault Detection 的超时时间。&lt;/p&gt;

&lt;p&gt;同样基于安全考虑做的变更还有监听的主机名。现在默认只监听本地 lo 网卡上。所以正式环境上需要修改配置为监听具体的网卡。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;network.host: &quot;192.168.0.2&quot; 
discovery.zen.minimum_master_nodes: 3
discovery.zen.ping_timeout: 100s
discovery.zen.fd.ping_timeout: 100s
discovery.zen.ping.unicast.hosts: [&quot;10.19.0.97&quot;,&quot;10.19.0.98&quot;,&quot;10.19.0.99&quot;,&quot;10.19.0.100&quot;]
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;上面的配置中，两个 timeout 可能会让人有所迷惑。这里的 &lt;strong&gt;fd&lt;/strong&gt; 是 fault detection 的缩写。也就是说：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;discovery.zen.ping_timeout 参数仅在加入或者选举 master 主节点的时候才起作用；&lt;/li&gt;
  &lt;li&gt;discovery.zen.fd.ping_timeout 参数则在稳定运行的集群中，master 检测所有节点，以及节点检测 master 是否畅通时长期有用。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;既然是长期有用，自然还有运行间隔和重试的配置，也可以根据实际情况调整：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;discovery.zen.fd.ping_interval: 10s
discovery.zen.fd.ping_retries: 10
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Sun, 06 Aug 2017 14:58:02 +0800</pubDate>
        <link>http://localhost:4000/elasticsearch-architecture/</link>
        <guid isPermaLink="true">http://localhost:4000/elasticsearch-architecture/</guid>
        
        <category>能工巧匠</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Elastic Stack安装教程</title>
        <description>&lt;h3 id=&quot;环境准备&quot;&gt;环境准备&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;CentOS7.1&lt;/li&gt;
  &lt;li&gt;JDK1.8&lt;/li&gt;
  &lt;li&gt;elasticsearch-5.4.3&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;jdk安装配置&quot;&gt;JDK安装配置&lt;/h3&gt;

&lt;p&gt;下载地址：http://download.oracle.com/otn-pub/java/jdk/8u111-b14/jdk-8u111-linux-x64.tar.gz&lt;/p&gt;

&lt;h3 id=&quot;elasticsearch安装配置&quot;&gt;elasticsearch安装配置&lt;/h3&gt;
&lt;h4 id=&quot;下载解压&quot;&gt;下载解压&lt;/h4&gt;

&lt;p&gt;使用命令从官网下载最新版本的Elasticsearch压缩包&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /var/wd
wget -N https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.4.3.tar.gz
tar -zxf elasticsearch-5.4.3.tar.gz
ln -s elasticsearch-5.4.3 elasticsearch
mkdir -p /var/data/elasticsearch
mkdir -p /var/logs/elasticsearch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;修改配置文件&quot;&gt;修改配置文件&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi elasticsearch/config/elasticsearch.yml

cluster.name: elasticstack
node.name: &quot;10.213.162.77&quot;
path.data: /var/data/elasticsearch
path.logs: /var/logs/elasticsearch
network.host: 0.0.0.0
http.port: 11200
discovery.zen.ping.unicast.hosts: [&quot;10.213.162.77&quot;, &quot;10.213.162.78&quot;, &quot;10.213.162.79&quot;]
discovery.zen.minimum_master_nodes: 3
transport.tcp.port: 11300
http.cors.enabled: true
http.cors.allow-origin: &quot;*&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi elasticsearch/config/jvm.options

-Xms32g
-Xmx32g
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;创建elasticsearch用户组以及elasticsearch用户&quot;&gt;创建elasticsearch用户组以及elasticsearch用户&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;groupadd elasticsearch
useradd  elasticsearch -g elasticsearch -p elasticsearch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;更改相关文件夹以及内部文件的所属用户以及组为elasticsearch&quot;&gt;更改相关文件夹以及内部文件的所属用户以及组为elasticsearch&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;chown -R elasticsearch:elasticsearch /var/wd/elasticsearch-5.4.3
chown -R elasticsearch:elasticsearch /var/data/elasticsearch
chown -R elasticsearch:elasticsearch /var/logs/elasticsearch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;修改服务器相关参数&quot;&gt;修改服务器相关参数&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;修改vm.map 限制
sysctl -w vm.max_map_count=262144
或
vi /etc/sysctl.conf
vm.max_map_count=262144

修改文件限制
ulimit -n 102400
或
vi /etc/security/limits.conf
elasticsearch hard nofile 102400
elasticsearch soft nofile 102400

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;切换到elasticsearch用户下启动&quot;&gt;切换到elasticsearch用户下启动&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;su elasticsearch
cd /var/wd/elasticsearch
./bin/elasticsearch
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;如果想在后台以守护进程模式运行&lt;/p&gt;

&lt;p&gt;打开另一个终端进行测试&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;curl  'http://10.213.162.77:11200'
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;你能看到以下返回信息：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;{
    name: &quot;10.213.162.77&quot;,
    cluster_name: &quot;elasticstack&quot;,
    cluster_uuid: &quot;aHySi7cBS76DyrIe74eIoA&quot;,
    version: {
        number: &quot;5.4.3&quot;,
        build_hash: &quot;5395e21&quot;,
        build_date: &quot;2016-12-06T12:36:15.409Z&quot;,
        build_snapshot: false,
        lucene_version: &quot;6.3.0&quot;
    },
    tagline: &quot;You Know, for Search&quot;
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;ELasticsearch集群已经启动并且正常运行。&lt;/p&gt;

&lt;h3 id=&quot;head安装配置&quot;&gt;head安装配置&lt;/h3&gt;

&lt;h4 id=&quot;安装node&quot;&gt;安装node&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /usr/local
wget -N https://nodejs.org/dist/v7.2.0/node-v7.2.0-linux-x64.tar.gz
tar -zxf node-v7.2.0-linux-x64.tar.gz
ln -s node-v7.2.0-linux-x64 node
vi /etc/profile
export PATH=$PATH:/usr/local/node/bin
source /etc/profile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;安装grunt&quot;&gt;安装grunt&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm install -g grunt-cli
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;安装head&quot;&gt;安装head&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git clone git://github.com/mobz/elasticsearch-head.git

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h5 id=&quot;修改gruntfilejs&quot;&gt;修改Gruntfile.js&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;connect: {
    server: {
        options: {
            port: 11100,
            hostname: '*',
            base: '.',
            keepalive: true
        }
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;修改appjs&quot;&gt;修改app.js&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;this.base_uri = this.config.base_uri || this.prefs.get(&quot;app-base_uri&quot;) || &quot;http://10.213.162.77:11200&quot;;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h5 id=&quot;运行head&quot;&gt;运行head&lt;/h5&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;npm install 
grunt server
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;kibana安装配置&quot;&gt;Kibana安装配置&lt;/h3&gt;

&lt;p&gt;使用命令从官网下载最新版本的Elasticsearch压缩包，按照文档的要求，一般情况下kibana的版本必须和Elasticsearch安装的版本一致。&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /var/wd
wget -N https://artifacts.elastic.co/downloads/kibana/kibana-5.4.3-linux-x86_64.tar.gz
tar -zxf kibana-5.4.3-linux-x86_64.tar.gz
ln -s kibana-5.4.3 kibana
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi kibana/config/kibana.yml

server.port: 11601
server.host: &quot;0.0.0.0&quot;
elasticsearch.url: &quot;http://10.213.162.78:11200&quot;
elasticsearch.username: &quot;elastic&quot;
elasticsearch.password: &quot;elastic&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h3 id=&quot;x-pack安装配置&quot;&gt;X-Pack安装配置&lt;/h3&gt;

&lt;p&gt;X-Pack是一个Elastic Stack的扩展，将安全，警报，监视，报告和图形功能包含在一个易于安装的软件包中。在Elasticsearch 5.0.0之前，您必须安装单独的Shield，Watcher和Marvel插件才能获得在X-Pack中所有的功能。&lt;/p&gt;

&lt;h4 id=&quot;elasticsearch下载x-pack&quot;&gt;Elasticsearch下载X-Pack&lt;/h4&gt;

&lt;p&gt;在es的根目录（每个节点），运行 &lt;code class=&quot;highlighter-rouge&quot;&gt;bin/elasticsearch-plugin&lt;/code&gt; 进行安装&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bin/elasticsearch-plugin install x-pack
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;如果你在Elasticsearch已禁用自动索引的创建，在&lt;code class=&quot;highlighter-rouge&quot;&gt;elasticsearch.yml&lt;/code&gt;配置&lt;code class=&quot;highlighter-rouge&quot;&gt;action.auto_create_index&lt;/code&gt;允许X-pack创造以下指标&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;action.auto_create_index: .security,.monitoring*,.watches,.triggered_watches,.watcher-history*
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;kibana下载x-pack&quot;&gt;Kibana下载X-Pack&lt;/h4&gt;

&lt;p&gt;在Kibana根目录运行 &lt;code class=&quot;highlighter-rouge&quot;&gt;bin/kibana-plugin&lt;/code&gt; 进行安装&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bin/kibana-plugin install x-pack
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;验证x-pack&quot;&gt;验证X-Pack&lt;/h4&gt;

&lt;p&gt;在浏览器上输入： &lt;code class=&quot;highlighter-rouge&quot;&gt;http://10.213.162.77:11601&lt;/code&gt; ，可以打开Kibana，此时需要输入用户名和密码登录，默认分别是 &lt;code class=&quot;highlighter-rouge&quot;&gt;elastic&lt;/code&gt; 和 &lt;code class=&quot;highlighter-rouge&quot;&gt;changeme&lt;/code&gt;&lt;/p&gt;

&lt;h3 id=&quot;安装参考&quot;&gt;安装参考&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;每个操作系统安装Elasticsearch的文件选择不同，参考：&lt;code class=&quot;highlighter-rouge&quot;&gt;https://www.elastic.co/downloads/elasticsearch&lt;/code&gt;，选择对应的文件下载。&lt;/li&gt;
  &lt;li&gt;安装Kiabna需要根据操作系统做选择，参考：&lt;code class=&quot;highlighter-rouge&quot;&gt;https://www.elastic.co/guide/en/kibana/current/install.html&lt;/code&gt;，选择对应的文件下载。&lt;/li&gt;
  &lt;li&gt;安装X-Pack需要根据Elasticsearch安装不同的方式提供不同的安装方法，参考：&lt;code class=&quot;highlighter-rouge&quot;&gt;https://www.elastic.co/guide/en/x-pack/5.4/installing-xpack.html#installing-xpack&lt;/code&gt;。&lt;/li&gt;
  &lt;li&gt;离线安装&lt;/li&gt;
&lt;/ol&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;./bin/elasticsearch-plugin install file:///var/wd/x-pack-5.4.3.zip
./bin/kibana-plugin install file:///var/wd/x-pack-5.4.3.zip
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;App&lt;/th&gt;
      &lt;th&gt;URL&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;x-pack&lt;/td&gt;
      &lt;td&gt;https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.4.3.zip&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h3 id=&quot;logstash安装&quot;&gt;Logstash安装&lt;/h3&gt;

&lt;p&gt;Logstash 是一款强大的数据处理工具，它可以实现数据传输，格式处理，格式化输出，还有强大的插件功能，常用于日志处理。&lt;/p&gt;

&lt;h4 id=&quot;logstash版本要求&quot;&gt;logstash版本要求&lt;/h4&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Kafka Client Version&lt;/th&gt;
      &lt;th&gt;Logstash Version&lt;/th&gt;
      &lt;th&gt;Plugin Version&lt;/th&gt;
      &lt;th&gt;Why&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;0.8&lt;/td&gt;
      &lt;td&gt;2.0.0 - 2.x.x&lt;/td&gt;
      &lt;td&gt;&amp;lt;3.0.0&lt;/td&gt;
      &lt;td&gt;Legacy, 0.8 is still popular&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0.9&lt;/td&gt;
      &lt;td&gt;2.0.0 - 2.3.x&lt;/td&gt;
      &lt;td&gt;3.x.x&lt;/td&gt;
      &lt;td&gt;Works with the old Ruby Event API (event[‘product’][‘price’] = 10)&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0.9&lt;/td&gt;
      &lt;td&gt;2.4.x - 5.x.x&lt;/td&gt;
      &lt;td&gt;4.x.x&lt;/td&gt;
      &lt;td&gt;Works with the new getter/setter APIs (event.set(‘[product][price]’, 10))&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;0.10.0.x&lt;/td&gt;
      &lt;td&gt;2.4.x - 5.x.x&lt;/td&gt;
      &lt;td&gt;5.x.x&lt;/td&gt;
      &lt;td&gt;Not compatible with the ⇐ 0.9 broker&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h4 id=&quot;logstash下载安装&quot;&gt;logstash下载安装&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /var/wd/
wget -c https://artifacts.elastic.co/downloads/logstash/logstash-5.4.3.tar.gz
tar -xzvf logstash-5.4.3.tar.gz
ln -s logstash-5.4.3 logstash
cd logstash
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;日志采集filebeat配置&quot;&gt;日志采集filebeat配置&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir plugin-config
vi plugin-config/filebeat.conf

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input {
    beats {
        port =&amp;gt; &quot;11044&quot;
    }
}

filter {
   grok {
        match =&amp;gt; [&quot;message&quot;, &quot;%{TIMESTAMP_ISO8601:timestamp} \[%{SYSLOGPROG:thread}\] %{LOGLEVEL:level}&quot;]
        remove_field =&amp;gt; [ &quot;beat&quot;,&quot;tags&quot;,&quot;type&quot;,&quot;program&quot;]
        add_field =&amp;gt; {&quot;app&quot; =&amp;gt; &quot;%{[fields][app]}&quot; }
      }
   ruby {
        code =&amp;gt; &quot;event.set('esUpdateTime', event.get('@timestamp').time.localtime + 8*60*60)
        event.set('type', event.get('app'))&quot;
      }
  }
  
output {
  kafka {
   # codec =&amp;gt; plain {
   #    format =&amp;gt; &quot;%{message}&quot;
   # }
    codec =&amp;gt; json
    topic_id =&amp;gt; &quot;feeds-log&quot;
    bootstrap_servers =&amp;gt; &quot;10.213.131.140:12015,10.213.45.168:12015,10.213.59.97:12015,10.213.59.99:12015&quot;
    compression_type =&amp;gt; &quot;snappy&quot;
  }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h4 id=&quot;日志转发kafka配置&quot;&gt;日志转发kafka配置&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;mkdir plugin-config
vi plugin-config/kafka.conf

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;input{
    kafka{
        codec =&amp;gt; &quot;json&quot;
        group_id =&amp;gt; &quot;feeds-log-logstash&quot;
        topics =&amp;gt; [&quot;feeds-log&quot;]
        bootstrap_servers =&amp;gt; &quot;10.213.131.140:12015,10.213.45.168:12015,10.213.59.97:12015,10.213.59.99:12015&quot;
    }
}

filter {
   grok {
        match =&amp;gt; [&quot;message&quot;, &quot;%{TIMESTAMP_ISO8601:timestamp} \[%{SYSLOGPROG:thread}\] %{LOGLEVEL:level}&quot;]
        overwrite =&amp;gt; [&quot;timestamp&quot;,&quot;thread&quot;,&quot;level&quot;]
        remove_field =&amp;gt; [ &quot;beat&quot;,&quot;tags&quot;,&quot;program&quot;,&quot;fields&quot;]
    }
output{
    elasticsearch{
        hosts=&amp;gt;[&quot;10.213.131.131:11200&quot;,&quot;10.213.131.132:11200&quot;,&quot;10.213.131.132:11200&quot;]
        index =&amp;gt; &quot;feeds-log-%{+YYYYMM}&quot;
        document_type =&amp;gt; &quot;%{type}&quot;
        #flush_size=&amp;gt;20000
        #idle_flush_time=&amp;gt;10
        #template_overwrite=&amp;gt;true
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;启动logstash&quot;&gt;启动logstash&lt;/h4&gt;

&lt;p&gt;控台启动，观察错误日志，没问题在后台启动&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;bin/logstash -f plugin-config/filebeat.conf --config.reload.automatic
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h3 id=&quot;filebeat安装&quot;&gt;Filebeat安装&lt;/h3&gt;

&lt;p&gt;Beats 平台是 Elastic.co 从 packetbeat 发展出来的数据收集器系统。beat 收集器可以直接写入 Elasticsearch，也可以传输给 Logstash。其中抽象出来的 libbeat，提供了统一的数据发送方法，输入配置解析，日志记录框架等功能。也就是说，所有的 beat 工具，在配置上，除了 input 以外，在output、filter、shipper、logging、run-options 上的配置规则都是完全一致的 ，filebeat是beat中的一员。&lt;/p&gt;

&lt;h4 id=&quot;filebeat下载&quot;&gt;filebeat下载&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;cd /var/wd/
wget -c https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.4.3-linux-x86_64.tar.gz
tar -xzvf filebeat-5.4.3-linux-x86_64.tar.gz
cd filebeat-5.4.3-linux-x86_64
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;这里安装的是bit版，也可以选择rpm版本安装&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;wget -c https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.4.3-x86_64.rpm

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;filebeat配置&quot;&gt;filebeat配置&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi filebeat.yml
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;添加数据源&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;- input_type: log

  # Paths that should be crawled and fetched. Glob based paths.
  paths:
    - /var/wd/feeds_api/logs/feeds_api_info.log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;添加字段标示产生日志应用&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;  fields:
     app: feeds-api
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;指定输出&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;output.logstash:
  # The Logstash hosts
  hosts: [&quot;10.213.131.132:11044&quot;,&quot;10.213.131.131:11044&quot;]
  worker: 2
  loadbalance: true
  index: feeds-log
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h4 id=&quot;启动关闭脚本&quot;&gt;启动关闭脚本&lt;/h4&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi startup.sh

#!/bin/bash
nohup ./filebeat -e -c filebeat.yml -d publish  &amp;amp;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;vi shutdown.sh

#!/bin/bash
runningPID=`pgrep -f &quot;./filebeat -e -c filebeat.yml -d publish&quot;`
if [ &quot;$runningPID&quot; ]; then
      echo &quot;filebeat pid: $runningPID&quot;
      kill -15 $runningPID
fi
sleep 2
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Thu, 18 May 2017 11:30:28 +0800</pubDate>
        <link>http://localhost:4000/elastic-stack/</link>
        <guid isPermaLink="true">http://localhost:4000/elastic-stack/</guid>
        
        <category>能工巧匠</category>
        
        
      </item>
    
      <item>
        <title>Lucene学习笔记</title>
        <description>&lt;blockquote&gt;
  &lt;p&gt;概要：&lt;/p&gt;

  &lt;ol&gt;
    &lt;li&gt;全文检索的原理和基本概念（铺垫）&lt;/li&gt;
    &lt;li&gt;Lucene简介，索引文档和检索文档的过程（主要）&lt;/li&gt;
    &lt;li&gt;Lucene 相似度评分算法（拓展）&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;全文检索原理铺垫&quot;&gt;全文检索原理（铺垫）&lt;/h1&gt;

&lt;h2 id=&quot;数据分类&quot;&gt;数据分类&lt;/h2&gt;

&lt;p&gt;生活中的数据总体分为三种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;结构化数据，固定格式和长度，如数据库数据，元数据等&lt;/li&gt;
  &lt;li&gt;非结构化数据，无固定格式和长度，如邮件，word文档，商品描述信息，非结构化数据也称为为全文数据&lt;/li&gt;
  &lt;li&gt;半结构化数据，如XML，HTML等，当然根据需要按结构化数据来处理，也可抽取出纯文本按非结构化数据来处理&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;搜索分类&quot;&gt;搜索分类&lt;/h2&gt;

&lt;p&gt;按照数据的分类，搜索也分为两种：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;对结构化数据的搜索，如对数据库的搜索，用SQL语句&lt;/li&gt;
  &lt;li&gt;对非结构化数据的搜索，如用Google和百度搜索&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;对非结构化数据全文数据搜索方法&quot;&gt;对非结构化数据（全文数据）搜索方法&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;顺序扫描法(Serial Scanning)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;从头到尾的扫描，比如windows的搜索文件，Linux下的grep命令，这种方法比较原始，但对于小数据量的文件，这种方法还是最直接，最方便的。但是对于大量的文件，这种方法就很慢了。&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;全文检索（Full-text Search）&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;有人可能会说，对非结构化数据顺序扫描很慢，对结构化数据的搜索却相对较快（由于结构化数据有一定的结构可以采取一定的搜索算法加快速度），那么把我们的非结构化数据想办法弄得有一定结构不就行了吗？&lt;/p&gt;

&lt;p&gt;这就是全文检索的基本思路：也即将非结构化数据中的一部分信息提取出来，重新组织，使其变得有一定结构，然后对此有一定结构的数据进行搜索，从而达到搜索相对较快的目的。&lt;/p&gt;

&lt;p&gt;这部分从非结构化数据中提取出的然后重新组织的信息，我们称之&lt;strong&gt;索引&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;直观的例子就是字典，可以按照偏旁部首和读音去找到对应的页数范围&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;这种先建立索引，再对索引进行搜索的过程就叫全文检索(Full-text Search)&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;全文检索的过程&quot;&gt;全文检索的过程&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/0060lm7Tly1fmpj7mitjgj30gs0et401.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;提出三个问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;索引里面究竟存些什么？(Index)&lt;/li&gt;
  &lt;li&gt;如何创建索引？(Indexing)&lt;/li&gt;
  &lt;li&gt;如何对索引进行搜索？(Search)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;索引里面究竟存些什么index&quot;&gt;索引里面究竟存些什么？(Index)&lt;/h3&gt;

&lt;p&gt;非结构化数据中所存储的信息：文件-&amp;gt;字符串&lt;/p&gt;

&lt;p&gt;而我们想搜索的是：字符串-&amp;gt;文件&lt;/p&gt;

&lt;p&gt;如果索引总能够保存从字符串到文件的映射，则会大大提高搜索速度。保存这种信息的索引称为&lt;strong&gt;反向索引&lt;/strong&gt;或者&lt;strong&gt;倒排索引&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;反向索引报错信息一般如下：
假设有100个文档，id为1-100，我们得到如下的结构&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/0060lm7Tly1fmpj86xoizj30gm04vq5w.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;左边报错的一系列字符串，称为&lt;strong&gt;词典&lt;/strong&gt;
右边的文档链表称为&lt;strong&gt;倒排表&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;比如说，我们要寻找包含字符”lucene”而且包含”solr”的文档，只需要下面几步：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;取出包含字符串“lucene”的文档链表。&lt;/li&gt;
  &lt;li&gt;取出包含字符串“solr”的文档链表。&lt;/li&gt;
  &lt;li&gt;通过合并链表，找出既包含“lucene”又包含“solr”的文件。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/0060lm7Tly1fmpj8jdbyrj30gu01qab2.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;索引反映出了全文搜索优势：一次索引，多次使用。&lt;/p&gt;

&lt;h3 id=&quot;如何创建索引indexing&quot;&gt;如何创建索引？(Indexing)&lt;/h3&gt;

&lt;p&gt;通过一个例子讲解&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第一步，准备一些要索引的文档（Document）&lt;/strong&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;文件一：Students should be allowed to go out with their friends, but not allowed to drink beer.&lt;/p&gt;

  &lt;p&gt;文件二：My friend Jerry went to school to see his students but found them drunk which is not allowed.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;&lt;strong&gt;第二步，将原文档传给分词组件（Tokenizer）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;分词组件做的几件事：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;将文档分成一个一个单独的单词&lt;/li&gt;
  &lt;li&gt;去除标点符号&lt;/li&gt;
  &lt;li&gt;去除停词(Stop word)：语言中最普通的一些单词，比如：the”,“a”，“this” 由于没有特别的意义，因而大多数情况下不能成为搜索的关键词&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;经过分词(Tokenizer)后得到的结果称为词元(Token)：
“Students”，“allowed”，“go”，“their”，“friends”，“allowed”，“drink”，“beer”，“My”，“friend”，“Jerry”，“went”，“school”，“see”，“his”，“students”，“found”，“them”，“drunk”，“allowed”。&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三步，将词元（Token）传给语言处理组件（Linguistic Processor）&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;对于英语，语言处理组件做的几件事：&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;变为小写(Lowercase)。&lt;/li&gt;
  &lt;li&gt;将单词缩减为词根形式，如“cars”到“car”等。这种操作称为：stemming。&lt;/li&gt;
  &lt;li&gt;将单词转变为词根形式，如“drove”到“drive”等。这种操作称为：lemmatization。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;语言处理组件(linguistic processor)的结果称为词(Term)&lt;/p&gt;

&lt;p&gt;在我们的例子中，经过语言处理，得到的词(Term)如下：&lt;/p&gt;

&lt;p&gt;“student”，“allow”，“go”，“their”，“friend”，“allow”，“drink”，“beer”，“my”，“friend”，“jerry”，“go”，“school”，“see”，“his”，“student”，“find”，“them”，“drink”，“allow”。&lt;/p&gt;

&lt;p&gt;也正是因为有语言处理的步骤，搜索“drive”，“driving”，“drove”，“driven”也能够被搜到,因为在我们的索引中，“driving”，“drove”，“driven”都会经过语言处理而变成“drive”，&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第四步，将得到的词(Term)传给索引组件(Indexer)&lt;/strong&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;利用得到的词(Term)创建一个字典。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://ww3.sinaimg.cn/large/0060lm7Tly1fmpj93rlavj30ca0h8aa5.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;2.对字典按字母顺序进行排序&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/0060lm7Tly1fmpj9em90yj30ca0h3aa5.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;合并相同的词(Term)成为文档倒排(Posting List)链表。&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/0060lm7Tly1fmpj9pqeklj30gn0evdoe.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在此表中，有几个定义：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Document Frequency 即文档频次，表示总共有多少文件包含此词(Term)。&lt;/li&gt;
  &lt;li&gt;Frequency 即词频率，表示此文件中包含了几个此词(Term)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;如何对索引进行搜索search&quot;&gt;如何对索引进行搜索？(Search)&lt;/h3&gt;

&lt;p&gt;&lt;strong&gt;第一步：用户输入查询语句&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第二步：搜索应用程序对用户输入查询语句进行词法分析，语法分析，及语言处理&lt;/strong&gt;
步骤和索引过程中的语言处理几乎相同&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第三步：搜索索引，得到符合语法树的文档&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;第四步：根据得到的文档和查询语句的相关性，对结果进行排序。&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;全文检索原理总结&quot;&gt;全文检索原理总结&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/0060lm7Tly1fmpja86blsj30gp0bjgr2.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;刚才说的信息检索技术(Information retrieval)中的基本理论，Lucene就是对这种基本理论的一种基本的的实践。&lt;/p&gt;

&lt;h1 id=&quot;lucene简介主要内容&quot;&gt;Lucene简介（主要内容）&lt;/h1&gt;

&lt;h2 id=&quot;概述&quot;&gt;概述&lt;/h2&gt;

&lt;p&gt;官网介绍：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Apache LuceneTM is a high-performance, full-featured text search engine library written entirely in Java. It is a technology suitable for nearly any application that requires full-text search, especially cross-platform.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;Lucene是一个高效的，可扩展的，基于Java的全文检索库&lt;/p&gt;

&lt;p&gt;要注意的是它不是一个完整的搜索应用程序，而是为你的应用程序提供索引和搜索功能，&lt;/p&gt;

&lt;p&gt;由于是它不是一个完整的搜索应用程序，所以有一些基于Lucene的开源搜索引擎产生，比如Elasticsearch和solr&lt;/p&gt;

&lt;h2 id=&quot;索引结构&quot;&gt;索引结构&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/0060lm7Tly1fmpjapbz19j30wt0l10v0.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;index
同一文件夹中的所有的文件构成一个Lucene 索引&lt;/li&gt;
  &lt;li&gt;Segment
一个索引可以包含多个段，段与段之间是独立的，添加新文档可以生成新的段，不同的段可以合并&lt;/li&gt;
  &lt;li&gt;Document&lt;/li&gt;
  &lt;li&gt;文档是我们建索引的基本单位，不同的文档是保存在不同的段中的，一个段可以包含多 个文档&lt;/li&gt;
  &lt;li&gt;Field
一篇文档包含不同类型的信息，可以分开索引，比如标题，时间，正文，作者等&lt;/li&gt;
  &lt;li&gt;Term
词是索引的最小单位，是经过词法分析和语言处理后的字符串&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;lucene 的索引结构中，即保存了正向信息，也保存了反向信息
正向：索引(Index) –&amp;gt; 段(segment) –&amp;gt; 文档
(Document) –&amp;gt; 域(Field) –&amp;gt; 词(Term)
反向：
词(Term) –&amp;gt; 文档(Document&lt;/p&gt;

&lt;p&gt;组件：
&lt;img src=&quot;http://ww3.sinaimg.cn/large/0060lm7Tly1fmpjb39imhj30ff0a3dil.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;被索引的文档用Document对象表示。&lt;/li&gt;
  &lt;li&gt;IndexWriter通过函数addDocument将文档添加到索引中，实现创建索引的过程&lt;/li&gt;
  &lt;li&gt;Lucene的索引是应用反向索引。&lt;/li&gt;
  &lt;li&gt;当用户有请求时，Query代表用户的查询语句。&lt;/li&gt;
  &lt;li&gt;IndexSearcher通过函数search搜索Lucene Index。&lt;/li&gt;
  &lt;li&gt;IndexSearcher计算term weight和score并且将结果返回给用户。&lt;/li&gt;
  &lt;li&gt;返回给用户的文档集合用TopDocsCollector表示。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;此图简单介绍全文检索的流程对应的Lucene实现的包结构：&lt;/p&gt;

&lt;p&gt;再详细到对Lucene API 的调用实现索引和搜索过程&lt;/p&gt;

&lt;h2 id=&quot;索引过程&quot;&gt;索引过程&lt;/h2&gt;

&lt;h3 id=&quot;核心类indexwriter&quot;&gt;核心类：IndexWriter&lt;/h3&gt;

&lt;p&gt;IndexWriter 是 Lucene 用来创建索引的一个核心的类，他的作用是把 Document 对象加到索引中。&lt;/p&gt;

&lt;p&gt;lucene6.5中构造方法：&lt;/p&gt;

&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot; style=&quot;&quot;&gt;&lt;pre&gt;&lt;div class=&quot;line&quot;&gt;1&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot; style=&quot;width: 679px;&quot;&gt;&lt;pre style=&quot;width: 679px;&quot;&gt;&lt;div class=&quot;line&quot;&gt;public IndexWriter(Directory d, IndexWriterConfig conf)&lt;/div&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;&lt;/figure&gt;

&lt;ul&gt;
  &lt;li&gt;Directory&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;这个类代表了 Lucene 的索引的存储的位置，这是一个抽象类，它目前有两个实现，第一个是 FSDirectory，它表示一个存储在文件系统中的索引的位置。第二个是 RAMDirectory，它表示一个存储在内存当中的索引的位置。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/0060lm7Tly1fmpjblem3nj30gm067aae.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IndexWriterConfig 是一个配置类，属性如下&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/0060lm7Tly1fmpjbvqdllj30fx0d0gm6.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;IndexWriterConfig主要包含了下面的信息：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;OpenMode 打开模式（CREATE-清空重建，APPEND-总是追加，CREATE_OR_APPEND-创建或追加）&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Analyzer
分析器  在一个文档被索引之前，首先需要对文档内容进行分词处理&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Similarity 影响打分的标准化因子(normalization
factor)部分，对文档的打分分两个部分，一部分是索引阶段计算的，与查询语句无关，一部分是搜索阶段计算的，与查询语句相关&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;Codec 编解码器 用来写入段的&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;MergePolicy 段合并策略&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;示例代码&quot;&gt;示例代码&lt;/h3&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Index {
    public static void main(String[] args) throws IOException {
        //写索引类
        IndexWriter writer;
        //索引目录
        String indexDir = &quot;C:\\lucene\\index&quot;;
        //储存方式
        Directory directory = FSDirectory.open(Paths.get(indexDir));
        //写索引类配置
        IndexWriterConfig config = new IndexWriterConfig(new StandardAnalyzer());
        config.setOpenMode(IndexWriterConfig.OpenMode.CREATE_OR_APPEND);
        writer = new IndexWriter(directory, config);
        //生成Document对象，Document对象就是对文档各个属性的封装
        String dataDir = &quot;C:\\lucene\\data\\123.txt&quot;;//文件，里边要有.txt文件
        File file = new File(dataDir);
        Document doc = new Document();
        doc.add(new Field(&quot;filename&quot;, file.getName(), TextField.TYPE_STORED));
        doc.add(new Field(&quot;contents&quot;, new FileReader(file), TextField.TYPE_NOT_STORED));
        //写入索引，将生成的Document（目录）对象写入到索引中
        writer.addDocument(doc);
        //关闭
        writer.close();
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;搜索过程&quot;&gt;搜索过程&lt;/h2&gt;

&lt;h3 id=&quot;核心类-indexsearcher&quot;&gt;核心类 IndexSearcher&lt;/h3&gt;

&lt;p&gt;IndexSearcher 是用来在建立好的索引上进行搜索的。它只能以只读的方式打开一个索引，所以可以有多个 IndexSearcher 的实例在一个索引上进行操作。&lt;/p&gt;

&lt;p&gt;步骤：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;IndexReader将磁盘上的索引信息读入到内存，INDEX_DIR就是索引文件存放的位置。&lt;/li&gt;
  &lt;li&gt;创建IndexSearcher准备进行搜索。&lt;/li&gt;
  &lt;li&gt;创建Analyer用来对查询语句进行词法分析和语言处理。&lt;/li&gt;
  &lt;li&gt;创建QueryParser用来对查询语句进行语法分析。&lt;/li&gt;
  &lt;li&gt;QueryParser调用parser进行语法分析，形成查询语法树，放到Query中。&lt;/li&gt;
  &lt;li&gt;IndexSearcher调用search对查询语法树Query进行搜索，得到结果TopDocs&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;示例代码：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;public class Searcher {
    //这个方法是搜索索引的方法，传入索引路径和查询表达式
    public static void search(String indexDir,String query) throws IOException, ParseException {
        //打开索引目录
        Directory dir= FSDirectory.open(Paths.get(indexDir));
        // 创建搜索的Query
        IndexSearcher searcher=new IndexSearcher(DirectoryReader.open(dir));
        // 使用标准的分词器
        Analyzer analyzer = new StandardAnalyzer();
        // 在content中搜索，创建parser确定要搜索的内容，其中，第2个参数为搜索的域
        QueryParser parser=new QueryParser(&quot;contents&quot;,analyzer);
        // 创建Query表示搜索域为content中，包含搜索内容为query1的文档
        Query query1=parser.parse(query);
        long start=System.currentTimeMillis();
        // 开始搜索
        TopDocs hits=searcher.search(query1,11);
        long end=System.currentTimeMillis();
        System.out.println(hits.totalHits);
        System.out.println(end-start);//计算搜搜时间等
        //获取搜索的地址等
        for(ScoreDoc scoreDoc:hits.scoreDocs){
            Document doc=searcher.doc(scoreDoc.doc);
            System.out.println(doc.get(&quot;fullpath&quot;));//地址，完整的
        }
    }
    public static void main(String[] args) throws IOException, ParseException {
        String indexDir=&quot;C:\\lucene\\index&quot;;//索引，index时建立的
        String query=&quot;food&quot;;//搜索的word
        search(indexDir, query);
    }
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;程序包和索引与搜索过程的对应关系&quot;&gt;程序包和索引与搜索过程的对应关系&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://ww2.sinaimg.cn/large/0060lm7Tly1fmpjce9bujj30f709wq7k.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Lucene的analysis模块主要负责词法分析及语言处理而形成Term。&lt;/li&gt;
  &lt;li&gt;Lucene的index模块主要负责索引的创建，里面有IndexWriter。&lt;/li&gt;
  &lt;li&gt;Lucene的store模块主要负责索引的读写。&lt;/li&gt;
  &lt;li&gt;Lucene的QueryParser主要负责语法分析。&lt;/li&gt;
  &lt;li&gt;Lucene的search模块主要负责对索引的搜索。&lt;/li&gt;
  &lt;li&gt;Lucene的similarity模块主要负责对相关性打分的实现。&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;第三部分lucene-相似度评分算法similarity&quot;&gt;第三部分：Lucene 相似度评分算法（similarity）&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;TF/IDF (词频/逆文档频率)算法，ES5.0之前，TF/IDF是默认的评分算法,TF/IDF源于&lt;strong&gt;向量空间模型(Vector Space Model)&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;BM25算法，ES5.0及之后（2017-05-04发布的5.4版本），BM25是默认的评分算法,BM25源于&lt;strong&gt;概率相关模型(probabilistic relevance model)&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;虽然听着好像差别巨大，但，两者都使用 词频, 逆文档频率 这些概念，且公式也很相似。&lt;strong&gt;其区别在于如何处理出现频繁的词&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;tfidf词频逆文档频率算法&quot;&gt;TF/IDF(词频/逆文档频率)算法&lt;/h2&gt;

&lt;h3 id=&quot;铺垫向量空间模型-vector-space-model&quot;&gt;铺垫：向量空间模型-Vector Space Model&lt;/h3&gt;

&lt;p&gt;问题：给定文档d 和 查询q，相似度如何计算呢？&lt;/p&gt;

&lt;p&gt;定义V(q) 和 V(d) 是 d和q 分词完成后，利用每个词出现次数所形成的向量&lt;/p&gt;

&lt;p&gt;相似度就等于文档d 和 查询q 的 加权查询向量V(q)和V(d)的 &lt;strong&gt;余弦相似度&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;计算文档得分需要考虑以下因子&quot;&gt;计算文档得分需要考虑以下因子&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;文档权重（document boost）：&lt;strong&gt;索引期&lt;/strong&gt;赋予某个文档的权重值&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;字段权重（field boost）:&lt;strong&gt;查询期&lt;/strong&gt;赋予某个字段的权重值&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;词频(trem frequency)：一个基于词项的因子，用来表示一个词项在某个文档中出现多少次，&lt;strong&gt;词频越高，文档得分越高&lt;/strong&gt; &lt;em&gt;比如：查询关键词是A，文档1和文档1都匹配上了，但是文档1中出现了2次A,文档2中出现了1次A,那么在这个项目中，文档1分数更高&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;逆文档频率(inverse document frequency):一个基于词项的因子,用来告诉评分公式该词项有多么&lt;strong&gt;罕见&lt;/strong&gt;，逆文档频率越低，词项越罕见，评分公式利用该因子为包含罕见词项的文档加权
&lt;em&gt;比如：查询关键词是A和B,如果文档1命中了A,文档2命中了B,但是在整个文档范围内，A出现的次数比B少，那么在这个项目中，文档1分数更高&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;协调因子（coord）：基于文档中词项命中个数的协调因子，&lt;strong&gt;一个文档中命中了查询中的词项越多，得分越高&lt;/strong&gt;
&lt;em&gt;比如：查询关键词被分词为A和B,如果文档1命中了A和B,文档2命中了A,那么在这个项目上，文档1的分数更高&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;长度范数(length norm):每个字段的基于词项个数的归一化因子，一个字段包含的词项越多，改因子的权重越低，&lt;em&gt;*这意味着lucene评分公式更”喜欢”包含更少词项的字段&lt;/em&gt;
&lt;em&gt;比如：查询关键词是A,文档1和2都匹配上了A,但是文档1内容长度比文档1短，那么在这个项目中，文档1分数更高&lt;/em&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;查询范数（query norm）：一个基于查询的归一化因子，它等于&lt;strong&gt;查询中词项的权重平方和&lt;/strong&gt;，&lt;strong&gt;查询范数使得不同查询的得分能相互比较，尽管这种比较通常是困难且不可行的&lt;/strong&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;tfidf评分公式&quot;&gt;TF/IDF评分公式&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;Lucene理论评分公式&lt;/strong&gt;
注意，你并不需要深入理解这个公式的来龙去脉，了解它的工作原理非常重要&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ww1.sinaimg.cn/large/0060lm7Tly1fmpjcs6s63j30mp039zkm.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;上面的公式理论形式糅合了布尔检索模型和向量空间检索模型，我们可以不讨论这个理论评分公式，直接跳到lucene实际评分公式
&lt;strong&gt;Lucene实际评分公式&lt;/strong&gt;
现在让我来看看Lucene实际评分公式：&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/0060lm7Tly1fmpjd34tfyj30mu02o0t3.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;解释：这是一个关于&lt;strong&gt;查询q&lt;/strong&gt;和&lt;strong&gt;文档d&lt;/strong&gt;的函数，有两个因子coord和queryNorm并不直接依赖查询词项，而是与查询词项的一个&lt;strong&gt;求和公式&lt;/strong&gt;相乘，&lt;strong&gt;求和公式&lt;/strong&gt;中的每个加数由以下因子连乘所得：词频 逆文档频率 词项权重 长度范数&lt;/p&gt;

&lt;p&gt;由这个公式我们可以导出一些规则：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;越多罕见的词项被匹配上，文档分数越高&lt;/li&gt;
  &lt;li&gt;文档字段越短，文档分数越高&lt;/li&gt;
  &lt;li&gt;权重越高（无论是索引期还查询期赋予的权重值），文档得分越高&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;bm25算法&quot;&gt;BM25算法&lt;/h2&gt;

&lt;p&gt;BM 是 Best Matching (最佳匹配) 的缩写，它被认为是 当今最先进的排序函数&lt;/p&gt;

&lt;p&gt;BM25源于 概率相关模型(probabilistic relevance mode), BM25和TF/IDF实际的打分函数有非常多的相似之处&lt;/p&gt;

&lt;p&gt;BM25 同样使用词频、逆向文档频率以及字段长归一化，但是每个因子的定义都有细微区别。与其详细解释 BM25 公式，不如将关注点放在 BM25 所能带来的实际好处上&lt;/p&gt;

&lt;p&gt;接下来对比下BM25与TFIDF的区别：&lt;/p&gt;

&lt;p&gt;对于词频，BM25 有一个上限，文档里出现 5 到 10 次的词会比那些只出现一两次的对相关度有着显著影响。，文档中出现 20 次的词几乎与那些出现上千次的词有着相同的影响。&lt;/p&gt;

&lt;h2 id=&quot;搜索流程映射到tfidf算法公式&quot;&gt;搜索流程映射到TF/IDF算法公式&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;http://ww4.sinaimg.cn/large/0060lm7Tly1fmpjddf3kyj30u90iidhk.jpg&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Mon, 06 Jun 2016 12:18:02 +0800</pubDate>
        <link>http://localhost:4000/luence-notes/</link>
        <guid isPermaLink="true">http://localhost:4000/luence-notes/</guid>
        
        <category>能工巧匠</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>使用MAT(Memory Analyzer Tool)分析内存泄漏</title>
        <description>&lt;p&gt;在工作中，有时会遇到OutOfMemoryError，我们知道遇到Error一般表明程序存在着严重问题，可能是灾难性的。所以找出是什么原因造成OutOfMemoryError非常重要。Memory Analyzer tool(MAT)来化解我们遇到的难题。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;从可用内存和请求数量的变化情况判断是突发性的内存泄露还是不断积累的结果换句话说，首先定位内存泄露的性质：&lt;/p&gt;

&lt;p&gt;突发内存泄露：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;表现：可用内存直线下降，短时间内消耗殆尽。&lt;/li&gt;
  &lt;li&gt;原因：定时任务执行、用户集中访问等，频繁调用有内存泄露的代码块。&lt;/li&gt;
  &lt;li&gt;排查：这种情况相对比较容易定位问题，查看可用内存骤降的时间点，从日志中查找对应时间点系统的行为（前提是日志必须很规范，有据可循）。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;隐式内存泄露：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;表现：可用内存持续下降，随着系统运行不断减少。&lt;/li&gt;
  &lt;li&gt;原因：偶发性调用到有内存泄露的代码块。&lt;/li&gt;
  &lt;li&gt;排查：这种情况需要借助dump文件和内存分析工具来排查。常用方式：在系统启动后获取dump文件，运行一段时间后（可用内存明显减少），再次获取dump文件（如果触发了JVM的OOM，可以直接拿到dump），对比前后两个时间点的内存占用情况，找出占用内存大幅增长的类。如果足够明显，可以直接从自动生成的dump文件中发现占用内存过多的类。&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;分析不同服务器的内存使用情况可以进一步缩小排查范围&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GLkC4/z6DV7.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GLZIg/SIDUg.jpg&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;使用jmap工具生成dump文件&quot;&gt;使用jmap工具生成dump文件&lt;/h3&gt;

&lt;p&gt;jmap是什么？简单来说，jmap是JDK自带的一种用于生成内存镜像文件的工具，通过该工具，开发人员可以快速生成dump文件。&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;进入目录：/usr/java/jdk1.6.0_33/bin&lt;/p&gt;

  &lt;p&gt;找到服务的进程ID：&lt;code class=&quot;highlighter-rouge&quot;&gt;ps –ef | grep search&lt;/code&gt;&lt;/p&gt;

  &lt;p&gt;执行命令：&lt;code class=&quot;highlighter-rouge&quot;&gt;jmap -dump:format=b,file=&amp;lt;path&amp;lt;PID&amp;gt;&lt;/code&gt;&lt;/p&gt;

  &lt;p&gt;下载dump文件至本地&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h3 id=&quot;mat工具的下载和安装&quot;&gt;MAT工具的下载和安装&lt;/h3&gt;

&lt;p&gt;MemoryAnalyzer.ini	可以设置最大/最小堆内存，与eclipse.ini配置类似&lt;/p&gt;

&lt;h3 id=&quot;使用mat工具进行内存泄露分析&quot;&gt;使用MAT工具进行内存泄露分析&lt;/h3&gt;

&lt;p&gt;当成功启动MAT后，通过菜单选项“File-&amp;gt;Open heap dump…”打开指定的dump文件后，将会生成Overview选项，在概况中可以初步查看占用内存最多的几个类以及对应的一些属性、引用层次和统计信息&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GMiDK/WVSID.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;在Overview选项中，以饼状图的形式列举出了程序内存消耗的一些基本信息，其中每一种不同颜色的饼块都代表了不同比例的内存消耗情况。如果说需要定位内存泄露的代码点，我们可以通过Dominator Tree菜单选项来进行排查(MAT工具仅仅只是一个辅助，分析OutofMemory并不存在一个固定的方式和准则，因此仔细观察和分析才能够找到问题所在)&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GMwlh/VM8YV.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Histogram图表中主要统计了消耗占比较高的类的实例数量及占用空间，Shallow Size: 对象自身占用的内存大小，不包括它引用的对象Retained Size: 当前对象大小 + 当前对象直接或间接引用的对象大小的总和 - 被GC Roots直接或间接引用的对象大小的总和&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GLXOt/jq1E4.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Top Consumers图表可以更直观地看到内存消耗占比最多的类，由于很多类都囊括在ClassLoader中，因此还需要进一步查看引用的层级。如果一次观察的结果不够明显，可以对比不同服务器（不同组）、不同时间点的内存使用情况，进一步缩小排查范围。&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GMkFO/WspKs.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;List objects with outgoing/incoming references 根据引用层级查看问题根源&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GMuF4/pSdwz.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;

&lt;p&gt;Leak suspects，MAT可以自动生成可疑泄露点的报告，能够从以下几点全面分析问题：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Shortest Paths To the Accumulation Point&lt;/li&gt;
  &lt;li&gt;Accumulated Objects in Dominator Tree&lt;/li&gt;
  &lt;li&gt;Accumulated Objects by Class in Dominator Tree&lt;/li&gt;
  &lt;li&gt;All Accumulated Objects by Class&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;http://pic.yupoo.com/hunng/ER0GNebl/kV2eP.png&quot; alt=&quot;&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Wed, 08 Jul 2015 18:21:16 +0800</pubDate>
        <link>http://localhost:4000/memory-analyzer-tool/</link>
        <guid isPermaLink="true">http://localhost:4000/memory-analyzer-tool/</guid>
        
        <category>能工巧匠</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Zookeeper、Solr和Tomcat安装配置实践</title>
        <description>&lt;h3 id=&quot;三台服务器&quot;&gt;三台服务器:&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;192.168.19.210(myid=210) master&lt;/li&gt;
  &lt;li&gt;192.168.19.211(myid=211) slave1&lt;/li&gt;
  &lt;li&gt;192.168.19.212(myid=212) slave2&lt;/li&gt;
&lt;/ul&gt;

&lt;!-- more --&gt;

&lt;h3 id=&quot;zookeeper集群配置&quot;&gt;ZooKeeper集群配置&lt;/h3&gt;

&lt;p&gt;安装ZooKeeper集群，在上面3分节点上分别安装，使用的版本是zookeeper-3.4.5。首先在master上安装配置：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /tmp
wget &lt;span class=&quot;nt&quot;&gt;-N&lt;/span&gt; http://mirrors.cnnic.cn/apache/zookeeper/zookeeper-3.4.5/zookeeper-3.4.5.tar.gz
&lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-zxf&lt;/span&gt; zookeeper-3.4.5.tar.gz
&lt;span class=&quot;nb&quot;&gt;mv&lt;/span&gt; ./zookeeper-3.4.5 /opt/zookeeper
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; /opt/zookeeper/data
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; /opt/zookeeper/logs
	
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'tickTime=2000'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'initLimit=10'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'syncLimit=5'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'dataDir=/opt/zookeeper/data'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'dataLogDir=/opt/zookeeper/logs'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'clientPort=2181'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'server.210=master:2888:3888'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'server.211=slave1:2888:3888'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'server.212=slave2:2888:3888'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/conf/zoo.cfg
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'210'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; /opt/zookeeper/data/myid&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;然后将master上的zookeeper复制到其他两个节点上：&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;scp -r /opt/zookeeper root@slave1:/opt/
scp -r /opt/zookeeper root@slave2:/opt/
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;修改slave1、slave2的myid文件：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;vi /opt/zookeeper/data/myid&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;其他设置：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;开机启动
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'/opt/zookeeper/bin/zkServer.sh start'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /etc/rc.d/rc.local
环境变量
&lt;span class=&quot;nb&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'export PATH=$PATH:/opt/zookeeper/bin'&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&amp;gt;&lt;/span&gt; /etc/profile
&lt;span class=&quot;nb&quot;&gt;source&lt;/span&gt; /etc/profile
ZooKeeper服务命令
/opt/zookeeper/bin/zkServer.sh start
/opt/zookeeper/bin/zkServer.sh status
/opt/zookeeper/bin/zkServer.sh stop
/opt/zookeeper/bin/zkServer.sh restart&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;solrcloud配置&quot;&gt;SolrCloud配置&lt;/h3&gt;

&lt;h5 id=&quot;首先在一个节点上对solr进行配置我们选择master节点&quot;&gt;首先在一个节点上对SOLR进行配置，我们选择master节点。&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /tmp
wget &lt;span class=&quot;nt&quot;&gt;-N&lt;/span&gt; http://archive.apache.org/dist/lucene/solr/4.2.1/solr-4.2.1.tgz
&lt;span class=&quot;nb&quot;&gt;tar&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-zxf&lt;/span&gt; solr-4.2.1.tgz
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/solr/webapps
&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt/solr/webapps
jar &lt;span class=&quot;nt&quot;&gt;-xf&lt;/span&gt; /tmp/solr-4.2.1/example/webapps/solr.war
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/solr/home&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;vi /opt/solr/home/solr.xml&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;solr&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;persistent=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
    &lt;span class=&quot;nt&quot;&gt;&amp;lt;cores&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;defaultCoreName=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Designer&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;adminPath=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/admin/cores&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;host=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${host:}&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;hostPort=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${jetty.port:}&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;zkClientTimeout=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${zkClientTimeout:15000}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
	 &lt;span class=&quot;nt&quot;&gt;&amp;lt;/cores&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/solr&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt; &lt;span class=&quot;c&quot;&gt;#master's lib&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;ln&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; /opt/solr/webapps/WEB-INF/lib /opt/solr/lib
 &lt;span class=&quot;c&quot;&gt;#master's conf&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/solr/conf&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;注意：这里并没有配置任何的core元素，等到整个配置安装完成之后，通过SOLR提供的REST接口，来实现Collection以及Shard的创建，从而来更新这些配置文件。&lt;/p&gt;

&lt;h4 id=&quot;zookeeper管理监控配置文件&quot;&gt;ZooKeeper管理监控配置文件:&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;&lt;span class=&quot;n&quot;&gt;java&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.:/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;solr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lib&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/*&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;org&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;apache&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;solr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;cloud&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;ZkCLI&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;cmd&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;upconfig&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;zkhost&lt;/span&gt; &lt;span class=&quot;nl&quot;&gt;master:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2181&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;slave1:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2181&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;nl&quot;&gt;slave1:&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2181&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confdir&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;solr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;conf&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Designer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;confname&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Designer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;solrhome&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;solr&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;home&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;检查一下ZooKeeper上的存储情况：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt/zookeeper
bin/zkCli.sh &lt;span class=&quot;nt&quot;&gt;-server&lt;/span&gt; master:2181
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /configs&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;tomcat配置与启动&quot;&gt;Tomcat配置与启动:&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; /opt/tomcat/conf/Catalina/localhost
vi /opt/tomcat/conf/Catalina/localhost/solr.xml&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;Context&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;docBase=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/opt/solr/webapps&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;reloadable=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
	  &lt;span class=&quot;nt&quot;&gt;&amp;lt;Environment&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;solr/home&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;type=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;java.lang.String&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;value=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/opt/solr/home&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;override=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/Context&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-java&quot; data-lang=&quot;java&quot;&gt;	
	&lt;span class=&quot;err&quot;&gt;#&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tomcat&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;catelina&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sh&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;vi&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;opt&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tomcat&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;bin&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;/&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;catalina&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;sh&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;JAVA_OPTS&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;
	 -Xmx6G
	 -Xms6G
	 -Xss256K
	 -Xmn2300M
	 -XX:SurvivorRatio=5
	 -XX:+UseParNewGC
	 -XX:PermSize=128M
	 -XX:MaxPermSize=128M
	 -XX:MaxDirectMemorySize=768m
	 -XX:LargePageSizeInBytes=128m
	 -XX:+DisableExplicitGC
	 -XX:SoftRefLRUPolicyMSPerMB=0
	 -XX:+OptimizeStringConcat
	 -XX:+UseFastAccessorMethods
	 -XX:CompileThreshold=100
	 -XX:+AggressiveOpts
	 -XX:+TieredCompilation
	 -XX:+DoEscapeAnalysis
	 -XX:+UseBiasedLocking
	 -XX:+EliminateLocks
	 -XX:BiasedLockingStartupDelay=0
	 -XX:+UseConcMarkSweepGC
	 -XX:CMSInitiatingOccupancyFraction=70
	 -XX:+UseCMSCompactAtFullCollection
	 -XX:CMSFullGCsBeforeCompaction=2
	 -XX:+CMSParallelRemarkEnabled
	 -XX:+UseCMSInitiatingOccupancyOnly
	 -XX:+CMSClassUnloadingEnabled
	 -XX:+CMSPermGenPrecleaningEnabled
	 -Dsun.net.inetaddr.ttl=0
	 -Dnetworkaddress.cache.ttl=30
	 -Djava.awt.headless=true
	 -DAllowManagedFieldsInDefaultFetchGroup=true
	 -DAllowMediatedWriteInDefaultFetchGroup=true
	 
	 -Djetty.port=8080
	 -DzkHost=master:2181,slave1:2181,slave2:2181
	 -DzkClientTimeout=15000
	&quot;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;tomcat 常用命令：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt; &lt;span class=&quot;c&quot;&gt;#启动&lt;/span&gt;
/opt/tomcat/bin/startup.sh
 &lt;span class=&quot;c&quot;&gt;#查看日志&lt;/span&gt;
&lt;span class=&quot;nb&quot;&gt;tail&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; /opt	/tomcat/logs/catalina.out&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;查看一下ZooKeeper中的数据状态：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cd&lt;/span&gt; /opt/zookeeper
bin/zkCli.sh &lt;span class=&quot;nt&quot;&gt;-server&lt;/span&gt; master:2181
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /live_nodes
&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; /collections&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;这时候，SolrCloud集群中只有一个活跃的节点，而且默认生成了一个Designer实例，这个实例实际上虚拟的，因为通过web界面无法访问master:8080/solr，看不到任何有关SolrCloud的信息.&lt;/p&gt;

&lt;h4 id=&quot;同步数据和配置信息启动其他节点&quot;&gt;同步数据和配置信息，启动其他节点&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;scp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; /opt/tomcat/ root@slave1:/opt/
scp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; /opt/tomcat/ root@slave2:/opt/
scp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; /opt/solr/ root@slave1:/opt/
scp &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; /opt/solr/ root@slave2:/opt/&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;启动其他Solr服务器节点：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;/opt/tomcat/bin/startup.sh&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;查看ZooKeeper集群中数据状态：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ls /live_nodes&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;这时已经存在3个活跃的节点了，但是SolrCloud集群并没有更多信息.&lt;/p&gt;
&lt;h4 id=&quot;创建collectionshard和replication&quot;&gt;创建Collection、Shard和Replication&lt;/h4&gt;
&lt;h4 id=&quot;创建collection及初始shard&quot;&gt;创建Collection及初始Shard&lt;/h4&gt;
&lt;p&gt;直接通过REST接口来创建Collection:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;root@master]&lt;span class=&quot;nv&quot;&gt;$ &lt;/span&gt;curl &lt;span class=&quot;s1&quot;&gt;'http://master:8080/solr/admin/collections?action=CREATE&amp;amp;name=Article&amp;amp;numShards=3&amp;amp;replicationFactor=1'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;如果成功，会输出如下响应内容：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;    &lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;response&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;4103&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;success&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
					&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
					&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;3367&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;str&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;core&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Article_shard2_replica1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;str&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;saved&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;/opt/solr/home/solr.xml&lt;span class=&quot;nt&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
					&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
					&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;3280&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;str&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;core&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Article_shard1_replica1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;str&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;saved&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;/opt/solr/home/solr.xml&lt;span class=&quot;nt&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;lst&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
					&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;0&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
					&lt;span class=&quot;nt&quot;&gt;&amp;lt;int&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;3690&lt;span class=&quot;nt&quot;&gt;&amp;lt;/int&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;str&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;core&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;Article_shard3_replica1&lt;span class=&quot;nt&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;str&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;saved&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;/opt/solr/home/solr.xml&lt;span class=&quot;nt&quot;&gt;&amp;lt;/str&amp;gt;&lt;/span&gt;
			&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;/lst&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/response&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;上面链接中的几个参数的含义，说明如下：&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;name                待创建Collection的名称&lt;/p&gt;

  &lt;p&gt;numShards           分片的数量&lt;/p&gt;

  &lt;p&gt;replicationFactor   复制副本的数量&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;执行上述操作如果没有异常，已经创建了一个Collection，名称为Article，而且每个节点上存在一个分片。这时，也可以查看ZooKeeper中状态：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ls /collections&lt;/code&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;ls /collections/Article&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;可以通过Web管理页面，访问master:8080/solr/#/~cloud，查看SolrCloud集群的分片信息.
我们从master节点可以看到，SOLR的配置文件内容，已经发生了变化，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cat /opt/solr/home/solr.xml&lt;/code&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;	&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;solr&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;persistent=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;cores&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;defaultCoreName=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Designer&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;host=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${host:}&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;adminPath=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/admin/cores&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;zkClientTimeout=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${zkClientTimeout:15000}&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;hostPort=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${jetty.port:}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
				&lt;span class=&quot;nt&quot;&gt;&amp;lt;core&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;loadOnStartup=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;shard=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;shard3&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;instanceDir=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard3_replica1/&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;transient=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard3_replica1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;collection=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;/cores&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/solr&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;创建replication&quot;&gt;创建Replication&lt;/h4&gt;
&lt;p&gt;下面对已经创建的初始分片进行复制。 shard1已经在slave1上，我们复制分片到master和slave2上，执行如下命令：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl &lt;span class=&quot;s1&quot;&gt;'http://master:8080/solr/admin/cores?action=CREATE&amp;amp;collection=Aritcle&amp;amp;name=Aritcle_shard1_replica_2&amp;amp;shard=shard1'&lt;/span&gt;
	&amp;lt;?xml &lt;span class=&quot;nv&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;
	&amp;lt;response&amp;gt;
		&amp;lt;lst &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
			&amp;lt;int &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;0&amp;lt;/int&amp;gt;
			&amp;lt;int &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;1485&amp;lt;/int&amp;gt;
		&amp;lt;/lst&amp;gt;
		&amp;lt;str &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;core&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;Aritcle_shard1_replica_2&amp;lt;/str&amp;gt;
		&amp;lt;str &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;saved&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/opt/solr/home/solr.xml&amp;lt;/str&amp;gt;
	&amp;lt;/response&amp;gt;
	
curl &lt;span class=&quot;s1&quot;&gt;'http://master:8080/solr/admin/cores?action=CREATE&amp;amp;collection=Aritcle&amp;amp;name=Aritcle_shard1_replica_3&amp;amp;shard=shard1'&lt;/span&gt;
	&amp;lt;?xml &lt;span class=&quot;nv&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;
	&amp;lt;response&amp;gt;
		&amp;lt;lst &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
			&amp;lt;int &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;0&amp;lt;/int&amp;gt;
			&amp;lt;int &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;2543&amp;lt;/int&amp;gt;
		&amp;lt;/lst&amp;gt;
		&amp;lt;str &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;core&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;Aritcle_shard1_replica_3&amp;lt;/str&amp;gt;
		&amp;lt;str &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;saved&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/opt/solr/home/solr.xml&amp;lt;/str&amp;gt;
	&amp;lt;/response&amp;gt;
	
curl &lt;span class=&quot;s1&quot;&gt;'http://master:8080/solr/admin/cores?action=CREATE&amp;amp;collection=Aritcle&amp;amp;name=Aritcle_shard1_replica_4&amp;amp;shard=shard1'&lt;/span&gt;
	&amp;lt;?xml &lt;span class=&quot;nv&quot;&gt;version&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;1.0&quot;&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;encoding&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;UTF-8&quot;&lt;/span&gt;?&amp;gt;
	&amp;lt;response&amp;gt;
		&amp;lt;lst &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;responseHeader&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;
			&amp;lt;int &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;0&amp;lt;/int&amp;gt;
			&amp;lt;int &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;QTime&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;2405&amp;lt;/int&amp;gt;
		&amp;lt;/lst&amp;gt;
		&amp;lt;str &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;core&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;Aritcle_shard1_replica_4&amp;lt;/str&amp;gt;
		&amp;lt;str &lt;span class=&quot;nv&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;saved&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;/opt/solr/home/solr.xml&amp;lt;/str&amp;gt;
	&amp;lt;/response&amp;gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;最后的结果是，slave1上的shard1，在master节点上有2个副本，名称为Article_shard1_replica_2和Article_shard1_replica_3，在slave2节点上有一个副本，名称为Article_shard1_replica_4. 也可以通过查看master和slave2上的目录变化，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ll /opt/solr/conf/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;总用量 24

drwxrwxr-x. 4 root root 4096 6月   1 09:58 Designer
drwxrwxr-x. 3 root root 4096 6月   1 15:41 Article_shard1_replica_2
drwxrwxr-x. 3 root root 4096 6月   1 15:42 Article_shard1_replica_3 
drwxrwxr-x. 3 hadoop root 4096 6月   1 15:23 Article_shard3_replica1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ll /opt/solr/conf/&lt;/code&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;总用量 20

drwxrwxr-x. 4 root root 4096 6月   1 14:53 Designer
drwxrwxr-x. 3 root root 4096 6月   1 15:44 Article_shard1_replica_4
drwxrwxr-x. 3 root root 4096 6月   1 15:23 Article_shard2_replica1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;其中，Article_shard3_replica1和Article_shard2_replica1都是创建Collection的时候自动生成的分片，也就是第一个副本。 通过Web界面，可以更加直观地看到shard1的情况.&lt;/p&gt;

&lt;p&gt;我们再次从master节点可以看到，SOLR的配置文件内容，又发生了变化，如下所示：&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;cat /opt/solr/home/solr.xml&lt;/code&gt;&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-xml&quot; data-lang=&quot;xml&quot;&gt;&lt;span class=&quot;cp&quot;&gt;&amp;lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot; ?&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;solr&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;persistent=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;cores&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;defaultCoreName=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Designer&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;host=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${host:}&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;adminPath=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;/admin/cores&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;zkClientTimeout=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${zkClientTimeout:15000}&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;hostPort=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;${jetty.port:}&quot;&lt;/span&gt;&lt;span class=&quot;nt&quot;&gt;&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;core&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;loadOnStartup=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;shard=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;shard3&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;instanceDir=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard3_replica1/&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;transient=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard3_replica1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;collection=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;core&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;loadOnStartup=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;shard=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;shard1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;instanceDir=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard1_replica_2/&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;transient=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard1_replica_2&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;collection=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
		&lt;span class=&quot;nt&quot;&gt;&amp;lt;core&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;loadOnStartup=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;true&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;shard=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;shard1&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;instanceDir=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard1_replica_3/&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;transient=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;false&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;name=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article_shard1_replica_3&quot;&lt;/span&gt; &lt;span class=&quot;na&quot;&gt;collection=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot;Article&quot;&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;/&amp;gt;&lt;/span&gt;
	&lt;span class=&quot;nt&quot;&gt;&amp;lt;/cores&amp;gt;&lt;/span&gt;
&lt;span class=&quot;nt&quot;&gt;&amp;lt;/solr&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;到此为止，我们已经基于3个物理节点，配置完成了SolrCloud集群。&lt;/p&gt;

</description>
        <pubDate>Tue, 10 Jun 2014 21:38:02 +0800</pubDate>
        <link>http://localhost:4000/zookeeper-solr-tomcat/</link>
        <guid isPermaLink="true">http://localhost:4000/zookeeper-solr-tomcat/</guid>
        
        <category>能工巧匠</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>用Octopress在Github搭建个人博客</title>
        <description>&lt;p&gt;一、安装Octopress运行的必要软件&lt;/p&gt;

&lt;!-- more --&gt;

&lt;p&gt;1.Octopress官网及软件下载：&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;
    &lt;p&gt;官方首页：&lt;a href=&quot;http://octopress.org&quot; title=&quot;http://octopress.org&quot;&gt;http://octopress.org&lt;/a&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里是RubyInstaller&lt;a href=&quot;http://pan.baidu.com/s/1eQotA0a&quot;&gt;下载地址&lt;/a&gt; （码：aurm）。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;这里是DevKit&lt;a href=&quot;http://pan.baidu.com/s/1hq1gIUS&quot;&gt;下载地址&lt;/a&gt; （码：vkd5）。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;2.安装RubyInstaller&lt;/p&gt;

&lt;p&gt;3.安装DevKit&lt;/p&gt;

&lt;p&gt;4.启动Ruby命令框，用CD的命令进入你存放DevKit的目录中，执行以下命令继续安装&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ruby dk.rb init&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;ruby dk.rb install&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;二、在本地安装Octopress博客系统&lt;/p&gt;

&lt;p&gt;1.要安装Octopress，就得先改变一个软件更新的源，因为默认的官方下载源已经被Q了。执行以下命令。&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;gem sources &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt; http://ruby.taobao.org/
gem sources &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; http://rubygems.org/
gem sources –l
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;2.然后执行：vi Gemfile 编辑配置文件，你也可以直接使用文本编辑器打开Gemfile，将第一行的source改成国内淘宝的。&lt;/p&gt;

&lt;p&gt;3.依次进入你存放博客的目录中，安装bundler。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;gem install bundler&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;bundle install&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;4.再安装Octopress默认的主题。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rake install&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;5.最后是生成和预览博客。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rake generate&lt;/code&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;rake preview&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;6.用的浏览器打开：localhost:4000，就可以看到Octopress博客效果了。&lt;/p&gt;

&lt;p&gt;三、更改电脑环境变量让Octopress支持中文&lt;/p&gt;

&lt;p&gt;1.我们需要改变一下我们计算机的环境变量，计算机–属性–高级系统设置–环境变量。&lt;/p&gt;

&lt;p&gt;2.新增 LANG 和 LC_ALL ，值都是 zh_CN.UTF-8。&lt;/p&gt;

&lt;p&gt;四、提交Octopress博客到Github免费空间&lt;/p&gt;

&lt;p&gt;1.先进入你的Github的本地项目中。&lt;/p&gt;

&lt;p&gt;2.连接Github服务器，填写你的Responsibility Url。&lt;/p&gt;

&lt;p&gt;3.然后再执行生成和提交命令。&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;rake setup_github_pages
rake generate
rake deploy&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;4.完成后，打开你的Github的二级域名后就可以看到刚刚提交的Octopress博客了。&lt;/p&gt;

&lt;p&gt;5.还可以直接使用Git来提交你的Octopress博客&lt;/p&gt;

&lt;p&gt;6.执行Octopress生成后，博客所有文件都存在一个Public的文件夹。你只要将这个Public中的文件复制或者直接上传到你的Github的空间也能实现浏览的效果。&lt;/p&gt;

&lt;p&gt;五、Octopress博客发布文章和新建页面&lt;/p&gt;

&lt;p&gt;1.发布一个文章前，先生成一个MD的文件，执行。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rake new_post[&quot;hello world&quot;]&lt;/code&gt; 它会在项目/source/_posts/中生成一个MD文件，类似2014-06-01-hello-world.markdown这样的。&lt;/p&gt;

&lt;p&gt;2.如果想要新建一个页面，则可以执行。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rake new_page[&quot;about&quot;]&lt;/code&gt; Octopress需要使用markdown语法，并不是常用的HtmL，学习markdown：http://wowubuntu.com/markdown/&lt;/p&gt;

&lt;p&gt;3.文章编辑完成后，就是生成和发布了。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rake generate&lt;/code&gt;
&lt;code class=&quot;highlighter-rouge&quot;&gt;rake deploy&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;4.本地预览可以用以下命令。&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;highlighter-rouge&quot;&gt;rake preview&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;5.退出预览是：Ctrl+C&lt;/p&gt;
</description>
        <pubDate>Fri, 06 Jun 2014 20:38:02 +0800</pubDate>
        <link>http://localhost:4000/github-octopress/</link>
        <guid isPermaLink="true">http://localhost:4000/github-octopress/</guid>
        
        <category>能工巧匠</category>
        
        
        <category>blog</category>
        
      </item>
    
      <item>
        <title>Git配置和常用命令</title>
        <description>&lt;p&gt;Git是一个分布式版本控制／软件配置管理软件，原来是linux内核开发者林纳斯·托瓦兹（Linus Torvalds）为了更好地管理linux内核开发而创立的。&lt;/p&gt;

&lt;!-- more --&gt;

&lt;h3 id=&quot;git配置&quot;&gt;Git配置&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; user.name &lt;span class=&quot;s2&quot;&gt;&quot;felics&quot;&lt;/span&gt;
git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; user.email &lt;span class=&quot;s2&quot;&gt;&quot;huangthink@gmail.com&quot;&lt;/span&gt;
git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; color.ui &lt;span class=&quot;nb&quot;&gt;true
&lt;/span&gt;git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; alias.co checkout
git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; alias.ci commit
git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; alias.st status
git config &lt;span class=&quot;nt&quot;&gt;--global&lt;/span&gt; alias.br branch
git config &lt;span class=&quot;nt&quot;&gt;-l&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 列举所有配置&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;用户的git配置文件在&lt;code class=&quot;highlighter-rouge&quot;&gt;~/.gitconfig&lt;/code&gt;，我的配置：&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&lt;span class=&quot;nb&quot;&gt;cat&lt;/span&gt; .gitconfig 
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;user]
	email &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; huangthink@gmail.com
	name &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; felics
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;color]
	ui &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; auto
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;color &lt;span class=&quot;s2&quot;&gt;&quot;branch&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
	current &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; yellow reverse
	&lt;span class=&quot;nb&quot;&gt;local&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; yellow
	remote &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; green
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;color &lt;span class=&quot;s2&quot;&gt;&quot;diff&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
	meta &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; yellow bold
	frag &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; magenta bold
	old &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; red bold
	new &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; green bold
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;color &lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
	added &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; yellow
	changed &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; green
	untracked &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; cyan
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;alias&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;]&lt;/span&gt;
	st &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;status&quot;&lt;/span&gt;
	co &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; checkout
	&lt;span class=&quot;nb&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;ls-files&quot;&lt;/span&gt;
	ci &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; commit
	br &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; branch
	rt &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; reset &lt;span class=&quot;nt&quot;&gt;--hard&lt;/span&gt;
	unstage &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; reset HEAD
	uncommit &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; reset &lt;span class=&quot;nt&quot;&gt;--soft&lt;/span&gt; HEAD^
	l &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; log &lt;span class=&quot;nt&quot;&gt;--pretty&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;oneline &lt;span class=&quot;nt&quot;&gt;--abbrev-commit&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--graph&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--decorate&lt;/span&gt;
   amend &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; commit &lt;span class=&quot;nt&quot;&gt;--amend&lt;/span&gt; 
   &lt;span class=&quot;nb&quot;&gt;who&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; shortlog &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-s&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--no-merges&lt;/span&gt; 
	g &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;grep&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-n&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--color&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-E&lt;/span&gt; 
	&lt;span class=&quot;nb&quot;&gt;cp&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; cherry-pick &lt;span class=&quot;nt&quot;&gt;-x&lt;/span&gt; 
	cb &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; checkout &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; 
&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;core]
	filemode &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;true&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;git常用命令&quot;&gt;Git常用命令&lt;/h3&gt;

&lt;h4 id=&quot;查看帮助命令&quot;&gt;查看、帮助命令&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git &lt;span class=&quot;nb&quot;&gt;help&lt;/span&gt; &amp;lt;&lt;span class=&quot;nb&quot;&gt;command&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 显示command的help&lt;/span&gt;
git show            &lt;span class=&quot;c&quot;&gt;# 显示某次提交的内容&lt;/span&gt;
git show &lt;span class=&quot;nv&quot;&gt;$id&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;查看提交记录&quot;&gt;查看提交记录&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git log
git log &amp;lt;file&amp;gt;      &lt;span class=&quot;c&quot;&gt;# 查看该文件每次提交记录&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &amp;lt;file&amp;gt;   &lt;span class=&quot;c&quot;&gt;# 显示版本历史，以及版本间的内容差异&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;-p&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-2&lt;/span&gt;       &lt;span class=&quot;c&quot;&gt;# 查看最近两次详细修改内容的diff&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;--stat&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# 查看提交统计信息&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;--since&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;6 hours&quot;&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 显示最近6小时提交&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;--before&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;2 days&quot;&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 显示2天前提交&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; HEAD~3          &lt;span class=&quot;c&quot;&gt;# 显示比HEAD早3个提交的那个提交&lt;/span&gt;
git log &lt;span class=&quot;nt&quot;&gt;-1&lt;/span&gt; HEAD^^^
git reflog				   &lt;span class=&quot;c&quot;&gt;# 查看操作记录&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;添加提交删除找回重置修改文件&quot;&gt;添加、提交、删除、找回，重置修改文件&lt;/h3&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git co  &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt; &amp;lt;file&amp;gt;   &lt;span class=&quot;c&quot;&gt;# 抛弃工作区修改&lt;/span&gt;
git co  &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# 抛弃工作区修改&lt;/span&gt;
git co HEAD &amp;lt;file&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 抛弃工作目录区中文件的修改&lt;/span&gt;
	
git add &amp;lt;file&amp;gt;      &lt;span class=&quot;c&quot;&gt;# 将工作文件修改提交到本地暂存区&lt;/span&gt;
git add &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# 将所有修改过的工作文件提交暂存区&lt;/span&gt;
	
git &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &amp;lt;file&amp;gt;       &lt;span class=&quot;c&quot;&gt;# 从版本库中删除文件&lt;/span&gt;
git &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &amp;lt;file&amp;gt; &lt;span class=&quot;nt&quot;&gt;--cached&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 从版本库中删除文件，但不删除文件&lt;/span&gt;
	
git reset &amp;lt;file&amp;gt;    &lt;span class=&quot;c&quot;&gt;# 从暂存区恢复到工作文件&lt;/span&gt;
git reset &lt;span class=&quot;nt&quot;&gt;--&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# 从暂存区恢复到工作文件&lt;/span&gt;
git reset &lt;span class=&quot;nt&quot;&gt;--hard&lt;/span&gt;  HEAD^ &lt;span class=&quot;c&quot;&gt;# 恢复最近一次提交过的状态，即放弃上次提交后的所有本次修改&lt;/span&gt;
git reset &lt;span class=&quot;nt&quot;&gt;--hard&lt;/span&gt; &amp;lt;commit &lt;span class=&quot;nb&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 恢复到某一次提交的状态&lt;/span&gt;
git reset HEAD &amp;lt;file&amp;gt; &lt;span class=&quot;c&quot;&gt;# 抛弃暂存区中文件的修改&lt;/span&gt;
	
git ci &amp;lt;file&amp;gt;
git ci &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
git ci &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# 将git add, git rm和git ci等操作都合并在一起做&lt;/span&gt;
git ci &lt;span class=&quot;nt&quot;&gt;-am&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;some comments&quot;&lt;/span&gt;
git ci &lt;span class=&quot;nt&quot;&gt;--amend&lt;/span&gt;      &lt;span class=&quot;c&quot;&gt;# 修改最后一次提交记录&lt;/span&gt;
	
git revert &amp;lt;&lt;span class=&quot;nv&quot;&gt;$id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;    &lt;span class=&quot;c&quot;&gt;# 恢复某次提交的状态，恢复动作本身也创建了一次提交对象&lt;/span&gt;
git revert HEAD     &lt;span class=&quot;c&quot;&gt;# 恢复最后一次提交的状态&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;查看文件diff&quot;&gt;查看文件diff&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git diff &amp;lt;file&amp;gt;     &lt;span class=&quot;c&quot;&gt;# 比较当前文件和暂存区文件差异&lt;/span&gt;
git diff
git diff &amp;lt;&lt;span class=&quot;nv&quot;&gt;$id1&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &amp;lt;&lt;span class=&quot;nv&quot;&gt;$id2&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;   	&lt;span class=&quot;c&quot;&gt;# 比较两次提交之间的差异&lt;/span&gt;
git diff &amp;lt;branch1&amp;gt;..&amp;lt;branch2&amp;gt;   &lt;span class=&quot;c&quot;&gt;# 在两个分支之间比较 &lt;/span&gt;
git diff &lt;span class=&quot;nt&quot;&gt;--staged&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 比较暂存区和版本库差异&lt;/span&gt;
git diff &lt;span class=&quot;nt&quot;&gt;--cached&lt;/span&gt;   &lt;span class=&quot;c&quot;&gt;# 比较暂存区和版本库差异&lt;/span&gt;
git diff &lt;span class=&quot;nt&quot;&gt;--stat&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 仅仅比较统计信息&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;git-本地分支管理&quot;&gt;Git 本地分支管理&lt;/h3&gt;

&lt;h4 id=&quot;查看切换创建和删除分支&quot;&gt;查看、切换、创建和删除分支&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git br &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# 查看远程分支&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# 查看各个分支最后提交信息&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;-a&lt;/span&gt;           &lt;span class=&quot;c&quot;&gt;# 列出所有分支&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;--merged&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 查看已经被合并到当前分支的分支&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;--no-merged&lt;/span&gt;  &lt;span class=&quot;c&quot;&gt;# 查看尚未被合并到当前分支的分支&lt;/span&gt;
git br &amp;lt;new_branch&amp;gt; &lt;span class=&quot;c&quot;&gt;# 基于当前分支创建新的分支&lt;/span&gt;
git br &amp;lt;new_branch&amp;gt;  &amp;lt;start_point&amp;gt;		&lt;span class=&quot;c&quot;&gt;# 基于另一个起点（分支名称，提交名称或则标签名称），创建新的分支&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;-f&lt;/span&gt; &amp;lt;existing_branch&amp;gt;  &amp;lt;start_point&amp;gt; &lt;span class=&quot;c&quot;&gt;# 创建同名新分支，覆盖已有分支&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;-d&lt;/span&gt; &amp;lt;branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 删除某个分支&lt;/span&gt;
git br &lt;span class=&quot;nt&quot;&gt;-D&lt;/span&gt; &amp;lt;branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 强制删除某个分支 (未被合并的分支被删除的时候需要强制)&lt;/span&gt;
	
git co &amp;lt;branch&amp;gt;     	&lt;span class=&quot;c&quot;&gt;# 切换到某个分支&lt;/span&gt;
git co &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &amp;lt;new_branch&amp;gt; 	&lt;span class=&quot;c&quot;&gt;# 创建新的分支，并且切换过去&lt;/span&gt;
git co &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &amp;lt;new_branch&amp;gt; &amp;lt;branch&amp;gt;  	  &lt;span class=&quot;c&quot;&gt;# 基于branch创建新的new_branch&lt;/span&gt;
git co &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &amp;lt;existing_branch&amp;gt; &amp;lt;new_branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 移动或重命名分支，当新分支不存在时&lt;/span&gt;
git co &lt;span class=&quot;nt&quot;&gt;-M&lt;/span&gt; &amp;lt;existing_branch&amp;gt; &amp;lt;new_branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 移动或重命名分支，当新分支存在时就覆盖&lt;/span&gt;
	
git co &lt;span class=&quot;nv&quot;&gt;$id&lt;/span&gt;         		 &lt;span class=&quot;c&quot;&gt;# 把某次历史提交记录checkout出来，但无分支信息，切换到其他分支会自动删除&lt;/span&gt;
git co &lt;span class=&quot;nv&quot;&gt;$id&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &amp;lt;new_branch&amp;gt;       &lt;span class=&quot;c&quot;&gt;# 把某次历史提交记录checkout出来，创建成一个分支&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;分支合并和rebase&quot;&gt;分支合并和rebase&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git merge &amp;lt;branch&amp;gt;                  &lt;span class=&quot;c&quot;&gt;# 将branch分支合并到当前分支&lt;/span&gt;
git merge origin/master &lt;span class=&quot;nt&quot;&gt;--no-ff&lt;/span&gt;     &lt;span class=&quot;c&quot;&gt;# 不要Fast-Foward合并，这样可以生成merge提交&lt;/span&gt;
git merge &lt;span class=&quot;nt&quot;&gt;--no-commit&lt;/span&gt; &amp;lt;branch&amp;gt;      &lt;span class=&quot;c&quot;&gt;# 合并但不提交&lt;/span&gt;
git merge &lt;span class=&quot;nt&quot;&gt;--squash&lt;/span&gt; &amp;lt;branch&amp;gt;         &lt;span class=&quot;c&quot;&gt;# 把一条分支上的内容合并到另一个分支上的一个提交&lt;/span&gt;
	
git rebase master &amp;lt;branch&amp;gt;          &lt;span class=&quot;c&quot;&gt;# 将master rebase到branch，相当于：git co &amp;lt;branch&amp;gt; &amp;amp;&amp;amp; git rebase master &amp;amp;&amp;amp; git co master &amp;amp;&amp;amp; git merge &amp;lt;branch&amp;gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;git补丁管理&quot;&gt;Git补丁管理&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git diff &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; ../sync.patch         &lt;span class=&quot;c&quot;&gt;# 生成补丁&lt;/span&gt;
git apply ../sync.patch          &lt;span class=&quot;c&quot;&gt;# 打补丁&lt;/span&gt;
git apply &lt;span class=&quot;nt&quot;&gt;--check&lt;/span&gt; ../sync.patch  &lt;span class=&quot;c&quot;&gt;# 测试补丁能否成功&lt;/span&gt;
git format-patch &lt;span class=&quot;nt&quot;&gt;-X&lt;/span&gt;              &lt;span class=&quot;c&quot;&gt;# 根据提交的log生成patch，X为数字，表示最近的几个日志&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;git暂存管理&quot;&gt;Git暂存管理&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git stash                        &lt;span class=&quot;c&quot;&gt;# 暂存&lt;/span&gt;
git stash list                   &lt;span class=&quot;c&quot;&gt;# 列所有stash&lt;/span&gt;
git stash apply                  &lt;span class=&quot;c&quot;&gt;# 恢复暂存的内容&lt;/span&gt;
git stash drop                   &lt;span class=&quot;c&quot;&gt;# 删除暂存区&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;git远程分支管理&quot;&gt;Git远程分支管理&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git pull                         &lt;span class=&quot;c&quot;&gt;# 抓取远程仓库所有分支更新并合并到本地&lt;/span&gt;
git pull &lt;span class=&quot;nt&quot;&gt;--no-ff&lt;/span&gt;                 &lt;span class=&quot;c&quot;&gt;# 抓取远程仓库所有分支更新并合并到本地，不要快进合并&lt;/span&gt;
git fetch origin                 &lt;span class=&quot;c&quot;&gt;# 抓取远程仓库所有更新&lt;/span&gt;
git fetch origin remote-branch:local-branch &lt;span class=&quot;c&quot;&gt;#抓取remote-branch分支的更新&lt;/span&gt;
git fetch origin &lt;span class=&quot;nt&quot;&gt;--tags&lt;/span&gt; 		 &lt;span class=&quot;c&quot;&gt;# 抓取远程上的所有分支&lt;/span&gt;
git checkout &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &amp;lt;new-branch&amp;gt; &amp;lt;remote_tag&amp;gt; &lt;span class=&quot;c&quot;&gt;# 抓取远程上的分支&lt;/span&gt;
git merge origin/master          &lt;span class=&quot;c&quot;&gt;# 将远程主分支合并到本地当前分支&lt;/span&gt;
git co &lt;span class=&quot;nt&quot;&gt;--track&lt;/span&gt; origin/branch     &lt;span class=&quot;c&quot;&gt;# 跟踪某个远程分支创建相应的本地分支&lt;/span&gt;
git co &lt;span class=&quot;nt&quot;&gt;-b&lt;/span&gt; &amp;lt;local_branch&amp;gt; origin/&amp;lt;remote_branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 基于远程分支创建本地分支，功能同上&lt;/span&gt;
	
git push                         &lt;span class=&quot;c&quot;&gt;# push所有分支&lt;/span&gt;
git push origin master           &lt;span class=&quot;c&quot;&gt;# 将本地主分支推到远程主分支&lt;/span&gt;
git push &lt;span class=&quot;nt&quot;&gt;-u&lt;/span&gt; origin master        &lt;span class=&quot;c&quot;&gt;# 将本地主分支推到远程(如无远程主分支则创建，用于初始化远程仓库)&lt;/span&gt;
git push origin &amp;lt;local_branch&amp;gt;   &lt;span class=&quot;c&quot;&gt;# 创建远程分支， origin是远程仓库名&lt;/span&gt;
git push origin &amp;lt;local_branch&amp;gt;:&amp;lt;remote_branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;# 创建远程分支&lt;/span&gt;
git push origin :&amp;lt;remote_branch&amp;gt;  &lt;span class=&quot;c&quot;&gt;#先删除本地分支(git br -d &amp;lt;branch&amp;gt;)，然后再push删除远程分支&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h4 id=&quot;git远程仓库管理&quot;&gt;Git远程仓库管理&lt;/h4&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git remote &lt;span class=&quot;nt&quot;&gt;-v&lt;/span&gt;                    &lt;span class=&quot;c&quot;&gt;# 查看远程服务器地址和仓库名称&lt;/span&gt;
git remote show origin           &lt;span class=&quot;c&quot;&gt;# 查看远程服务器仓库状态&lt;/span&gt;
git remote add origin git@github:XXX/test.git         &lt;span class=&quot;c&quot;&gt;# 添加远程仓库地址&lt;/span&gt;
git remote set-url origin git@github.com:XXX/test.git &lt;span class=&quot;c&quot;&gt;# 设置远程仓库地址(用于修改远程仓库地址)&lt;/span&gt;
git remote &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &amp;lt;repository&amp;gt;       &lt;span class=&quot;c&quot;&gt;# 删除远程仓库&lt;/span&gt;
git remote set-head origin master   &lt;span class=&quot;c&quot;&gt;# 设置远程仓库的HEAD指向master分支&lt;/span&gt;
	
git branch &lt;span class=&quot;nt&quot;&gt;--set-upstream&lt;/span&gt; master origin/master
git branch &lt;span class=&quot;nt&quot;&gt;--set-upstream&lt;/span&gt; develop origin/develop&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;h3 id=&quot;实例&quot;&gt;实例&lt;/h3&gt;

&lt;h5 id=&quot;打patch过程&quot;&gt;打patch过程&lt;/h5&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;git add &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
git status
git diff &lt;span class=&quot;nt&quot;&gt;--cached&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt;XXX.patch
git ci &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s1&quot;&gt;'add patch'&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

</description>
        <pubDate>Fri, 25 Apr 2014 10:28:49 +0800</pubDate>
        <link>http://localhost:4000/git-configs-and-cammands/</link>
        <guid isPermaLink="true">http://localhost:4000/git-configs-and-cammands/</guid>
        
        <category>能工巧匠</category>
        
        
        <category>blog</category>
        
      </item>
    
  </channel>
</rss>
